{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import tensorflow as tf\n",
    "import itertools\n",
    "import operator\n",
    "import numpy as np\n",
    "import nltk\n",
    "import sys\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vocabulary_size = 8000\n",
    "unknown_token = \"UNKNOWN_TOKEN\"\n",
    "\n",
    "with open('groceries_mba.csv', 'r',encoding='utf-8') as f:\n",
    "    reader = csv.reader(f)\n",
    "    basket= [x for x in reader]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['citrus_fruit', 'semi-finished_bread', 'margarine', 'ready_soups'], 9835)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "basket[0], len(basket)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['citrus_fruit', 'semi-finished_bread', 'margarine', 'ready_soups'],\n",
       " ['tropical_fruit', 'yogurt', 'coffee'],\n",
       " ['whole_milk'],\n",
       " ['pip_fruit', 'yogurt', 'cream_cheese_', 'meat_spreads'],\n",
       " ['other_vegetables',\n",
       "  'whole_milk',\n",
       "  'condensed_milk',\n",
       "  'long_life_bakery_product'],\n",
       " ['whole_milk', 'butter', 'yogurt', 'rice', 'abrasive_cleaner'],\n",
       " ['rolls/buns'],\n",
       " ['other_vegetables',\n",
       "  'UHT-milk',\n",
       "  'rolls/buns',\n",
       "  'bottled_beer',\n",
       "  'liquor_(appetizer)'],\n",
       " ['pot_plants'],\n",
       " ['whole_milk', 'cereals']]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "basket[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('data.txt', 'wb') as f:\n",
    "    pickle.dump(basket, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open ('words.txt', 'rb') as fp:\n",
    "    wordlist = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('embeddings.txt','rb') as fp:\n",
    "    embeddings = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wordlist.append('UNKNOWN_TOKEN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "embeddings = np.vstack([embeddings, np.zeros(200)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(170, 170)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(wordlist), len(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "word_to_index = dict([(w,i) for i,w in enumerate(wordlist)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Instant_food_products': 99,\n",
       " 'UHT-milk': 38,\n",
       " 'UNKNOWN_TOKEN': 169,\n",
       " 'abrasive_cleaner': 128,\n",
       " 'artif._sweetener': 131,\n",
       " 'baby_cosmetics': 163,\n",
       " 'baby_food': 167,\n",
       " 'bags': 164,\n",
       " 'baking_powder': 63,\n",
       " 'bathroom_cleaner': 139,\n",
       " 'beef': 26,\n",
       " 'berries': 40,\n",
       " 'beverages': 50,\n",
       " 'bottled_beer': 12,\n",
       " 'bottled_water': 5,\n",
       " 'brandy': 124,\n",
       " 'brown_bread': 18,\n",
       " 'butter': 24,\n",
       " 'butter_milk': 48,\n",
       " 'cake_bar': 74,\n",
       " 'candles': 93,\n",
       " 'candy': 44,\n",
       " 'canned_beer': 14,\n",
       " 'canned_fish': 72,\n",
       " 'canned_fruit': 133,\n",
       " 'canned_vegetables': 81,\n",
       " 'cat_food': 56,\n",
       " 'cereals': 111,\n",
       " 'chewing_gum': 58,\n",
       " 'chicken': 30,\n",
       " 'chocolate': 28,\n",
       " 'chocolate_marshmallow': 91,\n",
       " 'citrus_fruit': 11,\n",
       " 'cleaner': 118,\n",
       " 'cling_film/bags': 78,\n",
       " 'cocoa_drinks': 144,\n",
       " 'coffee': 22,\n",
       " 'condensed_milk': 86,\n",
       " 'cooking_chocolate': 141,\n",
       " 'cookware': 138,\n",
       " 'cream': 153,\n",
       " 'cream_cheese_': 32,\n",
       " 'curd': 25,\n",
       " 'curd_cheese': 119,\n",
       " 'decalcifier': 152,\n",
       " 'dental_care': 110,\n",
       " 'dessert': 36,\n",
       " 'detergent': 59,\n",
       " 'dish_cleaner': 84,\n",
       " 'dishes': 65,\n",
       " 'dog_food': 94,\n",
       " 'domestic_eggs': 19,\n",
       " 'female_sanitary_products': 108,\n",
       " 'finished_products': 106,\n",
       " 'fish': 136,\n",
       " 'flour': 66,\n",
       " 'flower_(seeds)': 85,\n",
       " 'flower_soil/fertilizer': 147,\n",
       " 'frankfurter': 20,\n",
       " 'frozen_chicken': 162,\n",
       " 'frozen_dessert': 83,\n",
       " 'frozen_fish': 77,\n",
       " 'frozen_fruits': 154,\n",
       " 'frozen_meals': 46,\n",
       " 'frozen_potato_products': 96,\n",
       " 'frozen_vegetables': 29,\n",
       " 'fruit/vegetable_juice': 16,\n",
       " 'grapes': 57,\n",
       " 'hair_spray': 155,\n",
       " 'ham': 51,\n",
       " 'hamburger_meat': 39,\n",
       " 'hard_cheese': 55,\n",
       " 'herbs': 70,\n",
       " 'honey': 151,\n",
       " 'house_keeping_products': 97,\n",
       " 'hygiene_articles': 41,\n",
       " 'ice_cream': 53,\n",
       " 'instant_coffee': 102,\n",
       " 'jam': 115,\n",
       " 'ketchup': 123,\n",
       " 'kitchen_towels': 109,\n",
       " 'kitchen_utensil': 165,\n",
       " 'light_bulbs': 125,\n",
       " 'liqueur': 157,\n",
       " 'liquor': 80,\n",
       " 'liquor_(appetizer)': 100,\n",
       " 'liver_loaf': 117,\n",
       " 'long_life_bakery_product': 35,\n",
       " 'make_up_remover': 160,\n",
       " 'male_cosmetics': 120,\n",
       " 'margarine': 21,\n",
       " 'mayonnaise': 90,\n",
       " 'meat': 52,\n",
       " 'meat_spreads': 122,\n",
       " 'misc._beverages': 45,\n",
       " 'mustard': 76,\n",
       " 'napkins': 27,\n",
       " 'newspapers': 13,\n",
       " 'nut_snack': 134,\n",
       " 'nuts/prunes': 130,\n",
       " 'oil': 47,\n",
       " 'onions': 42,\n",
       " 'organic_products': 150,\n",
       " 'organic_sausage': 145,\n",
       " 'other_vegetables': 1,\n",
       " 'packaged_fruit/vegetables': 75,\n",
       " 'pasta': 71,\n",
       " 'pastry': 10,\n",
       " 'pet_care': 88,\n",
       " 'photo/film': 89,\n",
       " 'pickled_vegetables': 62,\n",
       " 'pip_fruit': 15,\n",
       " 'popcorn': 103,\n",
       " 'pork': 23,\n",
       " 'pot_plants': 67,\n",
       " 'potato_products': 137,\n",
       " 'preservation_products': 166,\n",
       " 'processed_cheese': 69,\n",
       " 'prosecco': 146,\n",
       " 'pudding_powder': 143,\n",
       " 'ready_soups': 148,\n",
       " 'red/blush_wine': 60,\n",
       " 'rice': 101,\n",
       " 'roll_products_': 87,\n",
       " 'rolls/buns': 2,\n",
       " 'root_vegetables': 6,\n",
       " 'rubbing_alcohol': 156,\n",
       " 'rum': 121,\n",
       " 'salad_dressing': 158,\n",
       " 'salt': 82,\n",
       " 'salty_snack': 34,\n",
       " 'sauces': 113,\n",
       " 'sausage': 9,\n",
       " 'seasonal_products': 73,\n",
       " 'semi-finished_bread': 64,\n",
       " 'shopping_bags': 8,\n",
       " 'skin_care': 129,\n",
       " 'sliced_cheese': 54,\n",
       " 'snack_products': 135,\n",
       " 'soap': 140,\n",
       " 'soda': 3,\n",
       " 'soft_cheese': 68,\n",
       " 'softener': 114,\n",
       " 'sound_storage_medium': 168,\n",
       " 'soups': 105,\n",
       " 'sparkling_wine': 112,\n",
       " 'specialty_bar': 49,\n",
       " 'specialty_cheese': 95,\n",
       " 'specialty_chocolate': 43,\n",
       " 'specialty_fat': 127,\n",
       " 'specialty_vegetables': 149,\n",
       " 'spices': 116,\n",
       " 'spread_cheese': 79,\n",
       " 'sugar': 37,\n",
       " 'sweet_spreads': 92,\n",
       " 'syrup': 132,\n",
       " 'tea': 126,\n",
       " 'tidbits': 142,\n",
       " 'toilet_cleaner': 161,\n",
       " 'tropical_fruit': 7,\n",
       " 'turkey': 98,\n",
       " 'vinegar': 107,\n",
       " 'waffles': 33,\n",
       " 'whipped/sour_cream': 17,\n",
       " 'whisky': 159,\n",
       " 'white_bread': 31,\n",
       " 'white_wine': 61,\n",
       " 'whole_milk': 0,\n",
       " 'yogurt': 4,\n",
       " 'zwieback': 104}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_to_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "169"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_to_index['UNKNOWN_TOKEN']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i, sent in enumerate(basket):\n",
    "    basket[i] = [w if w in word_to_index else unknown_token for w in sent]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "X_train = np.asarray([[word_to_index[w] for w in sent[:-1]] for sent in basket])\n",
    "y_train = np.asarray([[word_to_index[w] for w in sent[1:]] for sent in basket])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x:\n",
      "tropical_fruit other_vegetables white_bread bottled_water\n",
      "[7, 1, 31, 5]\n",
      "\n",
      "y:\n",
      "other_vegetables white_bread bottled_water chocolate\n",
      "[1, 31, 5, 28]\n"
     ]
    }
   ],
   "source": [
    "x_example, y_example = X_train[10], y_train[10]\n",
    "print(\"x:\\n%s\\n%s\" % (\" \".join([wordlist[x] for x in x_example]), x_example))\n",
    "print(\"\\ny:\\n%s\\n%s\" % (\" \".join([wordlist[x] for x in y_example]), y_example))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9835, (9835,))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train), X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[11, 64, 21], [7, 4], [], [15, 4, 32], [1, 0, 86], [0, 24, 4, 101],\n",
       "       [], [1, 38, 2, 12], [], [0]], dtype=object)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[64, 21, 148], [4, 22], [], [4, 32, 122], [0, 86, 35],\n",
       "       [24, 4, 101, 128], [], [38, 2, 12, 100], [], [111]], dtype=object)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train = np.array([var for var in X_train if var])\n",
    "y_train = np.array([var for var in y_train if var])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7676, 7676)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train), len(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7676,)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tropical_fruit',\n",
       " 'other_vegetables',\n",
       " 'white_bread',\n",
       " 'bottled_water',\n",
       " 'chocolate']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "basket[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.3684210526315788"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.average([len(row) for row in X_train])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "959"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = [len(row) for row in X_train]\n",
    "a.index(max(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "x = X_train\n",
    "y = y_train\n",
    "max_length =  10\n",
    "x_padded = []\n",
    "y_padded = []\n",
    "\n",
    "\n",
    "for row in x:\n",
    "    if len(row) <= max_length:\n",
    "        x_padded.append(row + [169] * (max_length - len(row)))\n",
    "    else :\n",
    "        x_padded.append(row[:10])\n",
    "\n",
    "for row in y:\n",
    "    if len(row) <= max_length:\n",
    "        y_padded.append(row + [169] * (max_length - len(row))) \n",
    "    else: \n",
    "        y_padded.append(row[:10])\n",
    "\n",
    "x_padded = np.array(x_padded)\n",
    "y_padded = np.array(y_padded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((7676, 10), (7676, 10))"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_padded.shape, y_padded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 64,  21, 148, ..., 169, 169, 169],\n",
       "       [  4,  22, 169, ..., 169, 169, 169],\n",
       "       [  4,  32, 122, ..., 169, 169, 169],\n",
       "       ..., \n",
       "       [ 11,   1,  24, ..., 121,  78, 169],\n",
       "       [  5,   3,  12, ..., 169, 169, 169],\n",
       "       [  7,   1, 107, ..., 169, 169, 169]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_padded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "170"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7676, 7676)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_padded),len(y_padded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xtrain, ytrain = x_padded[:7000], y_padded[:7000]\n",
    "xtest, ytest = x_padded[7000:7600], y_padded[7000:7600]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "from tensorflow.contrib import rnn \n",
    "hm_epochs = 150\n",
    "batch_size = 500\n",
    "num_steps = 10\n",
    "state_size = 200\n",
    "vocab_size = 170\n",
    "\n",
    "# Placeholders\n",
    "x = tf.placeholder(tf.int32, [None, num_steps]) # [batch_size, num_steps]\n",
    "seqlen = tf.placeholder(tf.int32, [None])\n",
    "y = tf.placeholder(tf.int32, [None, num_steps])\n",
    "\n",
    "def train_neural_network(x): \n",
    "    \n",
    "        def next_batch(step):\n",
    "            p,q = xtrain[batch_size*step:batch_size*(step+1)], ytrain[batch_size*step:batch_size*(step+1)]\n",
    "            return p,q\n",
    "        \n",
    "        def test_batch(stp):    \n",
    "            a,b = xtest[batch_size*stp:batch_size*(stp+1)], ytest[batch_size*stp:batch_size*(stp+1)]\n",
    "            return a,b\n",
    "              \n",
    "        def lstm_neural_network(x):\n",
    "            # Embedding layer\n",
    "            rnn_inputs = tf.nn.embedding_lookup(embeddings, x)\n",
    "            rnn_inputs = tf.cast(rnn_inputs, dtype=tf.float32)\n",
    "            print(rnn_inputs)\n",
    "            \n",
    "            # RNN\n",
    "            inputs = tf.unstack(rnn_inputs, num=num_steps, axis=1)   \n",
    "            cell = tf.contrib.rnn.GRUCell(state_size)\n",
    "            cell = tf.contrib.rnn.DropoutWrapper(cell=cell, output_keep_prob = 0.5)\n",
    "            print(\"this is rnn going in:\", rnn_inputs)\n",
    "            rnn_outputs, rnn_states = tf.contrib.rnn.static_rnn(cell, inputs, dtype=tf.float32)\n",
    "\n",
    "            rnn_output = tf.reshape(tf.concat(axis=1, values=rnn_outputs), [-1, state_size])\n",
    "            print(\"this is the output:\",rnn_output)\n",
    "            softmax_w = tf.get_variable(\"softmax_w\", [state_size, vocab_size], dtype=tf.float32)\n",
    "            softmax_b = tf.get_variable(\"softmax_b\", [vocab_size], dtype=tf.float32)\n",
    "            logits = tf.add(tf.matmul(rnn_output, softmax_w),softmax_b, name = \"logits\")\n",
    "            return logits\n",
    "\n",
    "        prediction = lstm_neural_network(x)\n",
    "        loss = tf.argmax(prediction, axis=1)\n",
    "        loss = tf.contrib.legacy_seq2seq.sequence_loss_by_example(\n",
    "            [prediction],\n",
    "            [tf.reshape(y[:batch_size], [-1])],\n",
    "            [tf.ones([batch_size * num_steps], dtype=tf.float32)])\n",
    "        cost = tf.reduce_sum(loss) / batch_size\n",
    "        optimizer = tf.train.AdamOptimizer().minimize(cost)   \n",
    "        saver = tf.train.Saver()\n",
    "        \n",
    "        with tf.Session() as sess:\n",
    "            sess.run(tf.initialize_all_variables())\n",
    "            for epoch in range(hm_epochs):\n",
    "                epoch_loss = 0 \n",
    "                for step in range(int(len(xtrain)/batch_size)):\n",
    "                    epoch_x, epoch_y = next_batch(step)\n",
    "                    _, c = sess.run([optimizer, cost], feed_dict={x: epoch_x, y: epoch_y})\n",
    "                    epoch_loss += c\n",
    "                print('Epoch', epoch, 'completed out of',hm_epochs,'loss:',epoch_loss)\n",
    "            save_path = saver.save(sess, \"./model\")\n",
    "            print(\"Model saved in file: %s\" % save_path)\n",
    "            \n",
    "            for stp in range(int(len(xtest)/batch_size)):\n",
    "                s,u = test_batch(stp)\n",
    "                correct = tf.equal((tf.argmax(prediction,1)),tf.cast(tf.reshape(tf.concat(axis=1, values= u), [-1]),tf.int64))\n",
    "                accuracy = tf.reduce_mean(tf.cast(correct, 'float'))\n",
    "                print( 'Batch #', stp, 'Accuracy by each batch:',accuracy.eval({x: s, y: u}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Cast:0\", shape=(?, 10, 200), dtype=float32)\n",
      "this is rnn going in: Tensor(\"Cast:0\", shape=(?, 10, 200), dtype=float32)\n",
      "this is the output: Tensor(\"Reshape:0\", shape=(?, 200), dtype=float32)\n",
      "WARNING:tensorflow:From <ipython-input-32-a01a1a3caf0a>:55: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Use `tf.global_variables_initializer` instead.\n",
      "Epoch 0 completed out of 150 loss: 556.398431778\n",
      "Epoch 1 completed out of 150 loss: 347.513626099\n",
      "Epoch 2 completed out of 150 loss: 299.957519531\n",
      "Epoch 3 completed out of 150 loss: 275.29476738\n",
      "Epoch 4 completed out of 150 loss: 257.599298477\n",
      "Epoch 5 completed out of 150 loss: 243.808303833\n",
      "Epoch 6 completed out of 150 loss: 233.546654701\n",
      "Epoch 7 completed out of 150 loss: 225.96871376\n",
      "Epoch 8 completed out of 150 loss: 220.064199448\n",
      "Epoch 9 completed out of 150 loss: 215.112513542\n",
      "Epoch 10 completed out of 150 loss: 211.90826416\n",
      "Epoch 11 completed out of 150 loss: 208.698615074\n",
      "Epoch 12 completed out of 150 loss: 206.27856636\n",
      "Epoch 13 completed out of 150 loss: 203.964692116\n",
      "Epoch 14 completed out of 150 loss: 202.261694908\n",
      "Epoch 15 completed out of 150 loss: 200.5947752\n",
      "Epoch 16 completed out of 150 loss: 199.520281792\n",
      "Epoch 17 completed out of 150 loss: 198.215078354\n",
      "Epoch 18 completed out of 150 loss: 196.933368683\n",
      "Epoch 19 completed out of 150 loss: 196.324912071\n",
      "Epoch 20 completed out of 150 loss: 195.230575562\n",
      "Epoch 21 completed out of 150 loss: 194.466225624\n",
      "Epoch 22 completed out of 150 loss: 193.890081406\n",
      "Epoch 23 completed out of 150 loss: 193.244960785\n",
      "Epoch 24 completed out of 150 loss: 192.156693459\n",
      "Epoch 25 completed out of 150 loss: 191.807808876\n",
      "Epoch 26 completed out of 150 loss: 191.089032173\n",
      "Epoch 27 completed out of 150 loss: 190.560376167\n",
      "Epoch 28 completed out of 150 loss: 190.069309235\n",
      "Epoch 29 completed out of 150 loss: 189.862430573\n",
      "Epoch 30 completed out of 150 loss: 189.330504417\n",
      "Epoch 31 completed out of 150 loss: 188.878171921\n",
      "Epoch 32 completed out of 150 loss: 188.070307732\n",
      "Epoch 33 completed out of 150 loss: 187.561348915\n",
      "Epoch 34 completed out of 150 loss: 187.360010147\n",
      "Epoch 35 completed out of 150 loss: 186.827902794\n",
      "Epoch 36 completed out of 150 loss: 186.292422295\n",
      "Epoch 37 completed out of 150 loss: 186.136540413\n",
      "Epoch 38 completed out of 150 loss: 185.690787315\n",
      "Epoch 39 completed out of 150 loss: 185.406603813\n",
      "Epoch 40 completed out of 150 loss: 185.120392799\n",
      "Epoch 41 completed out of 150 loss: 184.949809074\n",
      "Epoch 42 completed out of 150 loss: 184.548163414\n",
      "Epoch 43 completed out of 150 loss: 184.078888893\n",
      "Epoch 44 completed out of 150 loss: 183.576231956\n",
      "Epoch 45 completed out of 150 loss: 183.277099609\n",
      "Epoch 46 completed out of 150 loss: 182.729916573\n",
      "Epoch 47 completed out of 150 loss: 182.660579681\n",
      "Epoch 48 completed out of 150 loss: 182.26077652\n",
      "Epoch 49 completed out of 150 loss: 181.901545525\n",
      "Epoch 50 completed out of 150 loss: 181.68908596\n",
      "Epoch 51 completed out of 150 loss: 181.702766418\n",
      "Epoch 52 completed out of 150 loss: 181.039250374\n",
      "Epoch 53 completed out of 150 loss: 180.492358208\n",
      "Epoch 54 completed out of 150 loss: 180.368605614\n",
      "Epoch 55 completed out of 150 loss: 179.947300911\n",
      "Epoch 56 completed out of 150 loss: 179.594758034\n",
      "Epoch 57 completed out of 150 loss: 179.110625267\n",
      "Epoch 58 completed out of 150 loss: 178.974833488\n",
      "Epoch 59 completed out of 150 loss: 178.738283157\n",
      "Epoch 60 completed out of 150 loss: 178.618169785\n",
      "Epoch 61 completed out of 150 loss: 177.857055664\n",
      "Epoch 62 completed out of 150 loss: 177.743693352\n",
      "Epoch 63 completed out of 150 loss: 176.864797592\n",
      "Epoch 64 completed out of 150 loss: 177.107022285\n",
      "Epoch 65 completed out of 150 loss: 176.374580383\n",
      "Epoch 66 completed out of 150 loss: 176.045749664\n",
      "Epoch 67 completed out of 150 loss: 175.631803513\n",
      "Epoch 68 completed out of 150 loss: 175.268490791\n",
      "Epoch 69 completed out of 150 loss: 174.690139771\n",
      "Epoch 70 completed out of 150 loss: 174.615194321\n",
      "Epoch 71 completed out of 150 loss: 174.136162758\n",
      "Epoch 72 completed out of 150 loss: 174.106656075\n",
      "Epoch 73 completed out of 150 loss: 173.280213356\n",
      "Epoch 74 completed out of 150 loss: 173.150346756\n",
      "Epoch 75 completed out of 150 loss: 172.817332268\n",
      "Epoch 76 completed out of 150 loss: 172.083779335\n",
      "Epoch 77 completed out of 150 loss: 171.522809029\n",
      "Epoch 78 completed out of 150 loss: 171.555900574\n",
      "Epoch 79 completed out of 150 loss: 171.311429977\n",
      "Epoch 80 completed out of 150 loss: 171.259544373\n",
      "Epoch 81 completed out of 150 loss: 170.321345329\n",
      "Epoch 82 completed out of 150 loss: 169.523305893\n",
      "Epoch 83 completed out of 150 loss: 169.367323875\n",
      "Epoch 84 completed out of 150 loss: 168.812984467\n",
      "Epoch 85 completed out of 150 loss: 168.392079353\n",
      "Epoch 86 completed out of 150 loss: 168.026304245\n",
      "Epoch 87 completed out of 150 loss: 167.898817062\n",
      "Epoch 88 completed out of 150 loss: 167.696789742\n",
      "Epoch 89 completed out of 150 loss: 167.07216835\n",
      "Epoch 90 completed out of 150 loss: 165.944192886\n",
      "Epoch 91 completed out of 150 loss: 165.674793243\n",
      "Epoch 92 completed out of 150 loss: 165.3233881\n",
      "Epoch 93 completed out of 150 loss: 164.723596573\n",
      "Epoch 94 completed out of 150 loss: 164.430613518\n",
      "Epoch 95 completed out of 150 loss: 164.243374825\n",
      "Epoch 96 completed out of 150 loss: 164.04544735\n",
      "Epoch 97 completed out of 150 loss: 163.46041584\n",
      "Epoch 98 completed out of 150 loss: 162.68074131\n",
      "Epoch 99 completed out of 150 loss: 162.018190384\n",
      "Epoch 100 completed out of 150 loss: 162.042001724\n",
      "Epoch 101 completed out of 150 loss: 161.225073814\n",
      "Epoch 102 completed out of 150 loss: 160.979399681\n",
      "Epoch 103 completed out of 150 loss: 161.076229095\n",
      "Epoch 104 completed out of 150 loss: 161.095159531\n",
      "Epoch 105 completed out of 150 loss: 160.680045128\n",
      "Epoch 106 completed out of 150 loss: 161.282344818\n",
      "Epoch 107 completed out of 150 loss: 161.353881836\n",
      "Epoch 108 completed out of 150 loss: 159.901200294\n",
      "Epoch 109 completed out of 150 loss: 158.780674934\n",
      "Epoch 110 completed out of 150 loss: 158.133646011\n",
      "Epoch 111 completed out of 150 loss: 157.988546371\n",
      "Epoch 112 completed out of 150 loss: 159.2199049\n",
      "Epoch 113 completed out of 150 loss: 159.001736641\n",
      "Epoch 114 completed out of 150 loss: 158.2166605\n",
      "Epoch 115 completed out of 150 loss: 156.226822853\n",
      "Epoch 116 completed out of 150 loss: 155.49551487\n",
      "Epoch 117 completed out of 150 loss: 154.489113808\n",
      "Epoch 118 completed out of 150 loss: 154.190953255\n",
      "Epoch 119 completed out of 150 loss: 153.593980789\n",
      "Epoch 120 completed out of 150 loss: 153.213173866\n",
      "Epoch 121 completed out of 150 loss: 152.356225967\n",
      "Epoch 122 completed out of 150 loss: 152.358893394\n",
      "Epoch 123 completed out of 150 loss: 151.729602814\n",
      "Epoch 124 completed out of 150 loss: 151.37756443\n",
      "Epoch 125 completed out of 150 loss: 151.426163673\n",
      "Epoch 126 completed out of 150 loss: 151.269435883\n",
      "Epoch 127 completed out of 150 loss: 150.285108566\n",
      "Epoch 128 completed out of 150 loss: 150.067504883\n",
      "Epoch 129 completed out of 150 loss: 149.547128677\n",
      "Epoch 130 completed out of 150 loss: 149.606030464\n",
      "Epoch 131 completed out of 150 loss: 148.97294426\n",
      "Epoch 132 completed out of 150 loss: 148.654081345\n",
      "Epoch 133 completed out of 150 loss: 148.659880638\n",
      "Epoch 134 completed out of 150 loss: 148.617806435\n",
      "Epoch 135 completed out of 150 loss: 148.715669632\n",
      "Epoch 136 completed out of 150 loss: 149.571060181\n",
      "Epoch 137 completed out of 150 loss: 151.452868462\n",
      "Epoch 138 completed out of 150 loss: 151.594102859\n",
      "Epoch 139 completed out of 150 loss: 149.016046524\n",
      "Epoch 140 completed out of 150 loss: 146.07237339\n",
      "Epoch 141 completed out of 150 loss: 144.802386284\n",
      "Epoch 142 completed out of 150 loss: 144.044671059\n",
      "Epoch 143 completed out of 150 loss: 144.089790344\n",
      "Epoch 144 completed out of 150 loss: 143.684583664\n",
      "Epoch 145 completed out of 150 loss: 143.219035149\n",
      "Epoch 146 completed out of 150 loss: 142.364567757\n",
      "Epoch 147 completed out of 150 loss: 141.943664551\n",
      "Epoch 148 completed out of 150 loss: 141.10459137\n",
      "Epoch 149 completed out of 150 loss: 140.878116608\n",
      "Model saved in file: ./model\n",
      "Batch # 0 Accuracy by each batch: 0.634\n"
     ]
    }
   ],
   "source": [
    "train_neural_network(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tt = np.array(x_padded[7606:7676])\n",
    "tt[10:20] =  np.array(x_padded[7606:7616])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tt[10:20] = np.array([[  7,   0,  54,  17,  19,   21,  2,   5, 169, 169],\n",
    "       [  19,  9,   2, 169, 169, 169, 169, 169, 169, 169],\n",
    "       [ 86,   22,  2, 169, 169, 169, 169, 169, 169, 169],\n",
    "       [  10,  0,  50, 169, 169, 169, 169, 169, 169, 169],\n",
    "       [ 2,   0,   26,  81,  16,  33,  28, 169, 169, 169],\n",
    "       [ 11,  30, 169, 169, 169, 169, 169, 169, 169, 169],\n",
    "       [ 46,  29, 169, 169, 169, 169, 169, 169, 169, 169],\n",
    "       [  2,   0, 169, 169, 169, 169, 169, 169, 169, 169],\n",
    "       [ 39,   1,   18,  4,  10,  56, 128, 169, 169, 169],\n",
    "       [ 20,   1,   0,   7,  68, 119,  56,  41, 169, 169]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  7,   0,  17,  54,  19,   2,  21,   5, 169, 169],\n",
       "       [  9,  19,   2, 169, 169, 169, 169, 169, 169, 169],\n",
       "       [ 86,   2,  22, 169, 169, 169, 169, 169, 169, 169],\n",
       "       [  0,  50,  10, 169, 169, 169, 169, 169, 169, 169],\n",
       "       [ 26,   0,   2,  81,  16,  33,  28, 169, 169, 169],\n",
       "       [ 30,  11, 169, 169, 169, 169, 169, 169, 169, 169],\n",
       "       [ 29,  46, 169, 169, 169, 169, 169, 169, 169, 169],\n",
       "       [  0,   2, 169, 169, 169, 169, 169, 169, 169, 169],\n",
       "       [ 39,   1,   4,  18,  10,  56, 128, 169, 169, 169],\n",
       "       [ 20,   7,   1,   0,  68, 119,  56,  41, 169, 169],\n",
       "       [  7,   0,  54,  17,  19,  21,   2,   5, 169, 169],\n",
       "       [ 19,   9,   2, 169, 169, 169, 169, 169, 169, 169],\n",
       "       [ 86,  22,   2, 169, 169, 169, 169, 169, 169, 169],\n",
       "       [ 10,   0,  50, 169, 169, 169, 169, 169, 169, 169],\n",
       "       [  2,   0,  26,  81,  16,  33,  28, 169, 169, 169],\n",
       "       [ 11,  30, 169, 169, 169, 169, 169, 169, 169, 169],\n",
       "       [ 46,  29, 169, 169, 169, 169, 169, 169, 169, 169],\n",
       "       [  2,   0, 169, 169, 169, 169, 169, 169, 169, 169],\n",
       "       [ 39,   1,  18,   4,  10,  56, 128, 169, 169, 169],\n",
       "       [ 20,   1,   0,   7,  68, 119,  56,  41, 169, 169],\n",
       "       [ 52,   0,  24,  55, 169, 169, 169, 169, 169, 169],\n",
       "       [  9,   0,  17,  54, 169, 169, 169, 169, 169, 169],\n",
       "       [ 25,  46,  10,  35,  33, 169, 169, 169, 169, 169],\n",
       "       [  0, 169, 169, 169, 169, 169, 169, 169, 169, 169],\n",
       "       [  9,  51,   0,  22,   3, 169, 169, 169, 169, 169],\n",
       "       [  9,  42,  79,   5, 169, 169, 169, 169, 169, 169],\n",
       "       [ 38,  32,  22, 169, 169, 169, 169, 169, 169, 169],\n",
       "       [ 20,  26,  70,   0, 169, 169, 169, 169, 169, 169],\n",
       "       [  3, 169, 169, 169, 169, 169, 169, 169, 169, 169],\n",
       "       [ 11, 119, 128, 169, 169, 169, 169, 169, 169, 169]])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tt[:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sliced_cheese'"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordlist[54]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "These are results: [[ 0.00754669  0.44657511 -0.12729192 ...,  0.58057088  0.33615345\n",
      "  -0.02635901]\n",
      " [-0.0241589   0.5581727  -0.41380587 ...,  0.43316352  0.33038932\n",
      "  -0.30631232]\n",
      " [-0.25544032  0.08803369 -0.18636683 ..., -0.04221949  0.2560516\n",
      "  -0.2356609 ]\n",
      " ..., \n",
      " [-0.17675501 -0.05529821 -0.01411376 ...,  0.33081028 -0.14848122\n",
      "   0.17498448]\n",
      " [-0.02346693  0.14027222  0.06377    ...,  0.06751322 -0.17026943\n",
      "   0.23834445]\n",
      " [-0.12125824  0.16531292 -0.13084522 ...,  0.21480925 -0.12515812\n",
      "   0.25546247]]\n"
     ]
    }
   ],
   "source": [
    "sess=tf.Session()    \n",
    "#First let's load meta graph and restore weights\n",
    "saver = tf.train.import_meta_graph('model.meta')\n",
    "saver.restore(sess,tf.train.latest_checkpoint('./'))\n",
    "sess.run(tf.global_variables_initializer())\n",
    "graph = tf.get_default_graph()\n",
    "\n",
    "#context = graph.get_tensor_by_name(\"context:0\") \n",
    "#utterance = graph.get_tensor_by_name(\"utterance:0\")\n",
    "#target = graph.get_tensor_by_name(\"target:0\")\n",
    "\n",
    "op_to_restore = graph.get_tensor_by_name(\"logits:0\")\n",
    "#qe,an,lbl = test_batch(0)\n",
    "feed_dict={x: tt}\n",
    "results = sess.run(op_to_restore,feed_dict)\n",
    "print(\"These are results:\", results)\n",
    "results = np.reshape(results, [70, num_steps, vocab_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "r1= results.argmax(axis=2)[:20]\n",
    "r2=tt[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[167,  10,  78,  79,  34,  94, 132, 155,   0,  66],\n",
       "       [ 82,  82, 132, 139,  30, 113, 108, 118, 108, 139],\n",
       "       [101,  94, 139,  54,  78, 134,  78, 115,  95,  89],\n",
       "       [132, 108, 157,  43,  43,  43, 108, 108, 108, 123],\n",
       "       [135,  35,  38,  97, 102, 169, 129, 169, 169, 167],\n",
       "       [151,   1, 124,  99,  90,  29,  97,  97,  50, 123],\n",
       "       [ 43,  82,  82,  82,  82,  82,  82,  82,  82,  82],\n",
       "       [ 90, 132, 130,  31,  94, 108, 108, 147, 108,  29],\n",
       "       [  5,  34,  34,   6,  99,  56, 160,  37,  44, 158],\n",
       "       [115,  51,  34,  97,  97,  34,  79,  79,  79,  56],\n",
       "       [  1, 108,  70,  30,  94,   4,  43, 129,   0, 134],\n",
       "       [  6,  82, 143,  52,  98, 139,  81, 113,  74, 115],\n",
       "       [159,  95, 130, 130, 130,  79,  79,  89, 115,  89],\n",
       "       [117,  56,  21, 154, 108, 123,   5, 108,  21,  43],\n",
       "       [116,  55,  85,  53,  46, 167, 169,  53, 167, 167],\n",
       "       [ 26,  29, 124,  29, 108,  50, 108, 167,  14,  50],\n",
       "       [ 29,  82,  50,  82, 115,  82,  82, 116,  56,  82],\n",
       "       [132, 132, 108, 108,  29, 108, 108, 108, 108, 108],\n",
       "       [ 99,  34,  34, 138,  99,  56,  56,  25, 100,  56],\n",
       "       [147,  34, 138,  35, 131,   9,  25, 156,   1,  30]], dtype=int64)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  7,   0,  17,  54,  19,   2,  21,   5, 169, 169],\n",
       "       [  9,  19,   2, 169, 169, 169, 169, 169, 169, 169],\n",
       "       [ 86,   2,  22, 169, 169, 169, 169, 169, 169, 169],\n",
       "       [  0,  50,  10, 169, 169, 169, 169, 169, 169, 169],\n",
       "       [ 26,   0,   2,  81,  16,  33,  28, 169, 169, 169],\n",
       "       [ 30,  11, 169, 169, 169, 169, 169, 169, 169, 169],\n",
       "       [ 29,  46, 169, 169, 169, 169, 169, 169, 169, 169],\n",
       "       [  0,   2, 169, 169, 169, 169, 169, 169, 169, 169],\n",
       "       [ 39,   1,   4,  18,  10,  56, 128, 169, 169, 169],\n",
       "       [ 20,   7,   1,   0,  68, 119,  56,  41, 169, 169],\n",
       "       [  7,   0,  54,  17,  19,  21,   2,   5, 169, 169],\n",
       "       [ 19,   9,   2, 169, 169, 169, 169, 169, 169, 169],\n",
       "       [ 86,  22,   2, 169, 169, 169, 169, 169, 169, 169],\n",
       "       [ 10,   0,  50, 169, 169, 169, 169, 169, 169, 169],\n",
       "       [  2,   0,  26,  81,  16,  33,  28, 169, 169, 169],\n",
       "       [ 11,  30, 169, 169, 169, 169, 169, 169, 169, 169],\n",
       "       [ 46,  29, 169, 169, 169, 169, 169, 169, 169, 169],\n",
       "       [  2,   0, 169, 169, 169, 169, 169, 169, 169, 169],\n",
       "       [ 39,   1,  18,   4,  10,  56, 128, 169, 169, 169],\n",
       "       [ 20,   1,   0,   7,  68, 119,  56,  41, 169, 169]])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "root_vegetables,salt,pudding_powder,meat,turkey,bathroom_cleaner,canned_vegetables,sauces,cake_bar,jam\n",
    "\n",
    "salt,salt,syrup,bathroom_cleaner,chicken,sauces,female_sanitary_products,cleaner,female_sanitary_products,bathroom_cleaner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starts\n",
      "\n",
      "y': These are the predictions made \n",
      "baby_food,pastry,cling_film/bags,spread_cheese,salty_snack,dog_food,syrup,hair_spray,whole_milk,flour\n",
      "\n",
      "y These are the ground truths :\n",
      "tropical_fruit,whole_milk,whipped/sour_cream,sliced_cheese,domestic_eggs,rolls/buns,margarine,bottled_water,UNKNOWN_TOKEN,UNKNOWN_TOKEN\n",
      "End\n",
      "\n",
      "Starts\n",
      "\n",
      "y': These are the predictions made \n",
      "salt,salt,syrup,bathroom_cleaner,chicken,sauces,female_sanitary_products,cleaner,female_sanitary_products,bathroom_cleaner\n",
      "\n",
      "y These are the ground truths :\n",
      "sausage,domestic_eggs,rolls/buns,UNKNOWN_TOKEN,UNKNOWN_TOKEN,UNKNOWN_TOKEN,UNKNOWN_TOKEN,UNKNOWN_TOKEN,UNKNOWN_TOKEN,UNKNOWN_TOKEN\n",
      "End\n",
      "\n",
      "Starts\n",
      "\n",
      "y': These are the predictions made \n",
      "rice,dog_food,bathroom_cleaner,sliced_cheese,cling_film/bags,nut_snack,cling_film/bags,jam,specialty_cheese,photo/film\n",
      "\n",
      "y These are the ground truths :\n",
      "condensed_milk,rolls/buns,coffee,UNKNOWN_TOKEN,UNKNOWN_TOKEN,UNKNOWN_TOKEN,UNKNOWN_TOKEN,UNKNOWN_TOKEN,UNKNOWN_TOKEN,UNKNOWN_TOKEN\n",
      "End\n",
      "\n",
      "Starts\n",
      "\n",
      "y': These are the predictions made \n",
      "syrup,female_sanitary_products,liqueur,specialty_chocolate,specialty_chocolate,specialty_chocolate,female_sanitary_products,female_sanitary_products,female_sanitary_products,ketchup\n",
      "\n",
      "y These are the ground truths :\n",
      "whole_milk,beverages,pastry,UNKNOWN_TOKEN,UNKNOWN_TOKEN,UNKNOWN_TOKEN,UNKNOWN_TOKEN,UNKNOWN_TOKEN,UNKNOWN_TOKEN,UNKNOWN_TOKEN\n",
      "End\n",
      "\n",
      "Starts\n",
      "\n",
      "y': These are the predictions made \n",
      "snack_products,long_life_bakery_product,UHT-milk,house_keeping_products,instant_coffee,UNKNOWN_TOKEN,skin_care,UNKNOWN_TOKEN,UNKNOWN_TOKEN,baby_food\n",
      "\n",
      "y These are the ground truths :\n",
      "beef,whole_milk,rolls/buns,canned_vegetables,fruit/vegetable_juice,waffles,chocolate,UNKNOWN_TOKEN,UNKNOWN_TOKEN,UNKNOWN_TOKEN\n",
      "End\n",
      "\n",
      "Starts\n",
      "\n",
      "y': These are the predictions made \n",
      "honey,other_vegetables,brandy,Instant_food_products,mayonnaise,frozen_vegetables,house_keeping_products,house_keeping_products,beverages,ketchup\n",
      "\n",
      "y These are the ground truths :\n",
      "chicken,citrus_fruit,UNKNOWN_TOKEN,UNKNOWN_TOKEN,UNKNOWN_TOKEN,UNKNOWN_TOKEN,UNKNOWN_TOKEN,UNKNOWN_TOKEN,UNKNOWN_TOKEN,UNKNOWN_TOKEN\n",
      "End\n",
      "\n",
      "Starts\n",
      "\n",
      "y': These are the predictions made \n",
      "specialty_chocolate,salt,salt,salt,salt,salt,salt,salt,salt,salt\n",
      "\n",
      "y These are the ground truths :\n",
      "frozen_vegetables,frozen_meals,UNKNOWN_TOKEN,UNKNOWN_TOKEN,UNKNOWN_TOKEN,UNKNOWN_TOKEN,UNKNOWN_TOKEN,UNKNOWN_TOKEN,UNKNOWN_TOKEN,UNKNOWN_TOKEN\n",
      "End\n",
      "\n",
      "Starts\n",
      "\n",
      "y': These are the predictions made \n",
      "mayonnaise,syrup,nuts/prunes,white_bread,dog_food,female_sanitary_products,female_sanitary_products,flower_soil/fertilizer,female_sanitary_products,frozen_vegetables\n",
      "\n",
      "y These are the ground truths :\n",
      "whole_milk,rolls/buns,UNKNOWN_TOKEN,UNKNOWN_TOKEN,UNKNOWN_TOKEN,UNKNOWN_TOKEN,UNKNOWN_TOKEN,UNKNOWN_TOKEN,UNKNOWN_TOKEN,UNKNOWN_TOKEN\n",
      "End\n",
      "\n",
      "Starts\n",
      "\n",
      "y': These are the predictions made \n",
      "bottled_water,salty_snack,salty_snack,root_vegetables,Instant_food_products,cat_food,make_up_remover,sugar,candy,salad_dressing\n",
      "\n",
      "y These are the ground truths :\n",
      "hamburger_meat,other_vegetables,yogurt,brown_bread,pastry,cat_food,abrasive_cleaner,UNKNOWN_TOKEN,UNKNOWN_TOKEN,UNKNOWN_TOKEN\n",
      "End\n",
      "\n",
      "Starts\n",
      "\n",
      "y': These are the predictions made \n",
      "jam,ham,salty_snack,house_keeping_products,house_keeping_products,salty_snack,spread_cheese,spread_cheese,spread_cheese,cat_food\n",
      "\n",
      "y These are the ground truths :\n",
      "frankfurter,tropical_fruit,other_vegetables,whole_milk,soft_cheese,curd_cheese,cat_food,hygiene_articles,UNKNOWN_TOKEN,UNKNOWN_TOKEN\n",
      "End\n",
      "\n",
      "Starts\n",
      "\n",
      "y': These are the predictions made \n",
      "other_vegetables,female_sanitary_products,herbs,chicken,dog_food,yogurt,specialty_chocolate,skin_care,whole_milk,nut_snack\n",
      "\n",
      "y These are the ground truths :\n",
      "tropical_fruit,whole_milk,sliced_cheese,whipped/sour_cream,domestic_eggs,margarine,rolls/buns,bottled_water,UNKNOWN_TOKEN,UNKNOWN_TOKEN\n",
      "End\n",
      "\n",
      "Starts\n",
      "\n",
      "y': These are the predictions made \n",
      "root_vegetables,salt,pudding_powder,meat,turkey,bathroom_cleaner,canned_vegetables,sauces,cake_bar,jam\n",
      "\n",
      "y These are the ground truths :\n",
      "domestic_eggs,sausage,rolls/buns,UNKNOWN_TOKEN,UNKNOWN_TOKEN,UNKNOWN_TOKEN,UNKNOWN_TOKEN,UNKNOWN_TOKEN,UNKNOWN_TOKEN,UNKNOWN_TOKEN\n",
      "End\n",
      "\n",
      "Starts\n",
      "\n",
      "y': These are the predictions made \n",
      "whisky,specialty_cheese,nuts/prunes,nuts/prunes,nuts/prunes,spread_cheese,spread_cheese,photo/film,jam,photo/film\n",
      "\n",
      "y These are the ground truths :\n",
      "condensed_milk,coffee,rolls/buns,UNKNOWN_TOKEN,UNKNOWN_TOKEN,UNKNOWN_TOKEN,UNKNOWN_TOKEN,UNKNOWN_TOKEN,UNKNOWN_TOKEN,UNKNOWN_TOKEN\n",
      "End\n",
      "\n",
      "Starts\n",
      "\n",
      "y': These are the predictions made \n",
      "liver_loaf,cat_food,margarine,frozen_fruits,female_sanitary_products,ketchup,bottled_water,female_sanitary_products,margarine,specialty_chocolate\n",
      "\n",
      "y These are the ground truths :\n",
      "pastry,whole_milk,beverages,UNKNOWN_TOKEN,UNKNOWN_TOKEN,UNKNOWN_TOKEN,UNKNOWN_TOKEN,UNKNOWN_TOKEN,UNKNOWN_TOKEN,UNKNOWN_TOKEN\n",
      "End\n",
      "\n",
      "Starts\n",
      "\n",
      "y': These are the predictions made \n",
      "spices,hard_cheese,flower_(seeds),ice_cream,frozen_meals,baby_food,UNKNOWN_TOKEN,ice_cream,baby_food,baby_food\n",
      "\n",
      "y These are the ground truths :\n",
      "rolls/buns,whole_milk,beef,canned_vegetables,fruit/vegetable_juice,waffles,chocolate,UNKNOWN_TOKEN,UNKNOWN_TOKEN,UNKNOWN_TOKEN\n",
      "End\n",
      "\n",
      "Starts\n",
      "\n",
      "y': These are the predictions made \n",
      "beef,frozen_vegetables,brandy,frozen_vegetables,female_sanitary_products,beverages,female_sanitary_products,baby_food,canned_beer,beverages\n",
      "\n",
      "y These are the ground truths :\n",
      "citrus_fruit,chicken,UNKNOWN_TOKEN,UNKNOWN_TOKEN,UNKNOWN_TOKEN,UNKNOWN_TOKEN,UNKNOWN_TOKEN,UNKNOWN_TOKEN,UNKNOWN_TOKEN,UNKNOWN_TOKEN\n",
      "End\n",
      "\n",
      "Starts\n",
      "\n",
      "y': These are the predictions made \n",
      "frozen_vegetables,salt,beverages,salt,jam,salt,salt,spices,cat_food,salt\n",
      "\n",
      "y These are the ground truths :\n",
      "frozen_meals,frozen_vegetables,UNKNOWN_TOKEN,UNKNOWN_TOKEN,UNKNOWN_TOKEN,UNKNOWN_TOKEN,UNKNOWN_TOKEN,UNKNOWN_TOKEN,UNKNOWN_TOKEN,UNKNOWN_TOKEN\n",
      "End\n",
      "\n",
      "Starts\n",
      "\n",
      "y': These are the predictions made \n",
      "syrup,syrup,female_sanitary_products,female_sanitary_products,frozen_vegetables,female_sanitary_products,female_sanitary_products,female_sanitary_products,female_sanitary_products,female_sanitary_products\n",
      "\n",
      "y These are the ground truths :\n",
      "rolls/buns,whole_milk,UNKNOWN_TOKEN,UNKNOWN_TOKEN,UNKNOWN_TOKEN,UNKNOWN_TOKEN,UNKNOWN_TOKEN,UNKNOWN_TOKEN,UNKNOWN_TOKEN,UNKNOWN_TOKEN\n",
      "End\n",
      "\n",
      "Starts\n",
      "\n",
      "y': These are the predictions made \n",
      "Instant_food_products,salty_snack,salty_snack,cookware,Instant_food_products,cat_food,cat_food,curd,liquor_(appetizer),cat_food\n",
      "\n",
      "y These are the ground truths :\n",
      "hamburger_meat,other_vegetables,brown_bread,yogurt,pastry,cat_food,abrasive_cleaner,UNKNOWN_TOKEN,UNKNOWN_TOKEN,UNKNOWN_TOKEN\n",
      "End\n",
      "\n",
      "Starts\n",
      "\n",
      "y': These are the predictions made \n",
      "flower_soil/fertilizer,salty_snack,cookware,long_life_bakery_product,artif._sweetener,sausage,curd,rubbing_alcohol,other_vegetables,chicken\n",
      "\n",
      "y These are the ground truths :\n",
      "frankfurter,other_vegetables,whole_milk,tropical_fruit,soft_cheese,curd_cheese,cat_food,hygiene_articles,UNKNOWN_TOKEN,UNKNOWN_TOKEN\n",
      "End\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for pre,the in zip(r1,r2):\n",
    "    print(\"Starts\")\n",
    "    print(\"\\ny': These are the predictions made \\n%s\" % (\",\".join([wordlist[x] for x in pre])))\n",
    "    print(\"\\ny These are the ground truths :\\n%s\" % (\",\".join([wordlist[x] for x in the])))\n",
    "    print(\"End\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "white_bread,cocoa_drinks,pastry,nuts/prunes,hard_cheese,waffles,hard_cheese,chicken,margarine,beef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "result = np.reshape(results, [-1, vocab_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(700, 170)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "result = sess.run(tf.nn.softmax(result,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "qa = np.reshape(y_padded[7606:7676], [-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(700,)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "qb = result.argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(700,)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0 6.25392818451 0.00192289\n",
      "1 17 12.6874060631 0.00160685\n",
      "2 54 18.8751335144 0.00205449\n",
      "3 19 25.4457855225 0.00140088\n",
      "4 2 32.3433198929 0.00101027\n",
      "5 21 38.1614384651 0.00297319\n",
      "6 5 44.2671031952 0.0022302\n",
      "7 16 50.6720347404 0.00165338\n",
      "8 169 57.5053930283 0.00107723\n",
      "9 169 64.0146169662 0.00148963\n",
      "10 19 71.0393280983 0.000889625\n",
      "11 2 77.6624069214 0.00132933\n",
      "12 18 84.3062157631 0.00130206\n",
      "13 169 90.9073314667 0.00135885\n",
      "14 169 97.4097781181 0.00149977\n",
      "15 169 103.993902206 0.00138214\n",
      "16 169 110.77888298 0.00113063\n",
      "17 169 117.52573204 0.00117457\n",
      "18 169 124.119570255 0.00136878\n",
      "19 169 130.760578632 0.00130571\n",
      "20 2 137.57756424 0.00109502\n",
      "21 22 144.312800407 0.00118829\n",
      "22 13 151.310464382 0.000914014\n",
      "23 169 157.925091267 0.00134061\n",
      "24 169 164.591121674 0.00127344\n",
      "25 169 171.298449039 0.00122193\n",
      "26 169 178.045204163 0.00117468\n",
      "27 169 184.642576694 0.00136395\n",
      "28 169 191.292489052 0.00129414\n",
      "29 169 197.93434 0.00130461\n",
      "30 50 204.386339188 0.00157737\n",
      "31 10 211.397754192 0.000901532\n",
      "32 13 217.389939785 0.0024982\n",
      "33 169 223.629085064 0.00195152\n",
      "34 169 230.221031189 0.00137137\n",
      "35 169 236.551038265 0.00178202\n",
      "36 169 243.083768845 0.00145503\n",
      "37 169 249.556649685 0.00154477\n",
      "38 169 256.220460415 0.00127627\n",
      "39 169 262.886366367 0.0012736\n",
      "40 0 269.600785732 0.00121329\n",
      "41 2 276.069893837 0.00155061\n",
      "42 81 282.768768787 0.0012323\n",
      "43 16 289.752583027 0.000926762\n",
      "44 33 296.497375488 0.00117699\n",
      "45 28 302.920413494 0.00162372\n",
      "46 13 309.613372326 0.00123961\n",
      "47 169 316.553208351 0.000968428\n",
      "48 169 323.260175228 0.00122237\n",
      "49 169 329.898976803 0.00130859\n",
      "50 11 336.601937771 0.00122727\n",
      "51 114 342.927461624 0.00179003\n",
      "52 169 349.351777554 0.00162164\n",
      "53 169 355.899461746 0.00143343\n",
      "54 169 362.534314156 0.00131377\n",
      "55 169 369.154745579 0.00133286\n",
      "56 169 375.707985878 0.00142549\n",
      "57 169 382.2310853 0.00146911\n",
      "58 169 388.655033112 0.00162224\n",
      "59 169 395.202814102 0.00143329\n",
      "60 46 402.300694466 0.000826856\n",
      "61 8 408.575312614 0.00188351\n",
      "62 169 415.262640476 0.00124661\n",
      "63 169 421.798830032 0.00145\n",
      "64 169 428.569664955 0.00114674\n",
      "65 169 435.194507122 0.00132699\n",
      "66 169 441.771325111 0.00139227\n",
      "67 169 448.404082775 0.00131653\n",
      "68 169 455.050460339 0.00129872\n",
      "69 169 461.670584679 0.00133327\n",
      "70 2 468.578396797 0.000999943\n",
      "71 49 474.906941414 0.00178463\n",
      "72 169 481.624822617 0.0012091\n",
      "73 169 488.285919189 0.00127974\n",
      "74 169 494.683331013 0.00166586\n",
      "75 169 501.276838779 0.00136923\n",
      "76 169 507.907081604 0.00131984\n",
      "77 169 514.511346817 0.00135458\n",
      "78 169 521.122207165 0.00134567\n",
      "79 169 527.654287338 0.00145597\n",
      "80 1 534.543276787 0.00101894\n",
      "81 4 541.41836834 0.0010332\n",
      "82 18 548.302874565 0.00102352\n",
      "83 10 555.151792526 0.0010606\n",
      "84 56 562.1042943 0.00095624\n",
      "85 128 568.399982452 0.00184424\n",
      "86 65 574.84173727 0.00159361\n",
      "87 169 581.137252331 0.00184456\n",
      "88 169 587.617238522 0.00153383\n",
      "89 169 594.254582882 0.0013105\n",
      "90 7 600.741139412 0.00152379\n",
      "91 1 607.263400555 0.00147034\n",
      "92 0 613.455085754 0.00204638\n",
      "93 68 620.074735641 0.0013339\n",
      "94 119 626.483930588 0.00164635\n",
      "95 56 632.880484581 0.00166729\n",
      "96 41 639.16499567 0.00186497\n",
      "97 8 645.916574001 0.00116903\n",
      "98 169 652.609457493 0.0012397\n",
      "99 169 659.214325428 0.00135376\n",
      "100 15 665.761983395 0.00143347\n",
      "101 6 672.179300785 0.00163303\n",
      "102 4 679.01132822 0.00107867\n",
      "103 17 685.17861557 0.00209692\n",
      "104 32 692.063509464 0.00102312\n",
      "105 5 698.084511757 0.00242724\n",
      "106 110 704.754545689 0.00126836\n",
      "107 13 711.042645454 0.00185829\n",
      "108 169 717.624716282 0.00138498\n",
      "109 169 724.193626881 0.00140333\n",
      "110 10 730.886880875 0.00123924\n",
      "111 169 737.492789268 0.00135235\n",
      "112 169 744.212033749 0.00120745\n",
      "113 169 750.859598637 0.00129718\n",
      "114 169 757.536251545 0.00125999\n",
      "115 169 764.109505177 0.00139724\n",
      "116 169 770.672068596 0.00141226\n",
      "117 169 777.229088783 0.00142011\n",
      "118 169 783.781975269 0.00142599\n",
      "119 169 790.313614368 0.00145662\n",
      "120 32 796.8386693 0.00146624\n",
      "121 3 803.432962418 0.00136815\n",
      "122 33 809.907698631 0.00154191\n",
      "123 169 816.492591381 0.00138108\n",
      "124 169 823.116881847 0.00132772\n",
      "125 169 829.618015289 0.00150174\n",
      "126 169 836.201282978 0.00138332\n",
      "127 169 842.747259617 0.00143588\n",
      "128 169 849.31340456 0.00140721\n",
      "129 169 855.944698811 0.00131846\n",
      "130 22 862.481447697 0.00144919\n",
      "131 100 869.447781086 0.000943105\n",
      "132 60 876.45186758 0.000908163\n",
      "133 8 882.945675373 0.00151278\n",
      "134 169 889.692348957 0.00117478\n",
      "135 169 896.329174042 0.00131118\n",
      "136 169 903.178095341 0.0010606\n",
      "137 169 909.768647671 0.00137328\n",
      "138 169 916.472103596 0.00122667\n",
      "139 169 923.241320133 0.00114859\n",
      "140 15 930.068432331 0.00108398\n",
      "141 1 936.69752121 0.00132137\n",
      "142 38 943.241496563 0.00143876\n",
      "143 34 949.997380733 0.00116401\n",
      "144 169 956.926890373 0.000978481\n",
      "145 169 963.852050304 0.000982746\n",
      "146 169 970.658894539 0.00110618\n",
      "147 169 977.440360069 0.00113461\n",
      "148 169 984.152562618 0.00121598\n",
      "149 169 990.752317429 0.0013607\n",
      "150 59 997.266978264 0.00148156\n",
      "151 169 1003.8467803 0.00138812\n",
      "152 169 1010.34291553 0.00150926\n",
      "153 169 1016.89423275 0.00142823\n",
      "154 169 1023.51637983 0.00133057\n",
      "155 169 1030.10436392 0.00137681\n",
      "156 169 1036.69324446 0.00137558\n",
      "157 169 1043.28240871 0.00137519\n",
      "158 169 1049.76708317 0.00152666\n",
      "159 169 1056.32948494 0.00141249\n",
      "160 1 1062.73155355 0.00165812\n",
      "161 48 1069.2468338 0.00148064\n",
      "162 2 1075.52592516 0.0018751\n",
      "163 82 1082.23137903 0.00122422\n",
      "164 169 1088.86784697 0.00131165\n",
      "165 169 1095.56407881 0.00123556\n",
      "166 169 1102.48416519 0.000987745\n",
      "167 169 1109.17953777 0.00123662\n",
      "168 169 1115.86845398 0.00124463\n",
      "169 169 1122.62419224 0.00116418\n",
      "170 26 1129.30060291 0.00126029\n",
      "171 0 1136.4820857 0.000760539\n",
      "172 4 1143.24358845 0.00115749\n",
      "173 54 1149.61332893 0.0017126\n",
      "174 47 1156.04210091 0.00161443\n",
      "175 169 1162.17993736 0.00215959\n",
      "176 169 1168.6875124 0.00149209\n",
      "177 169 1175.24933052 0.00141331\n",
      "178 169 1181.6676445 0.0016314\n",
      "179 169 1188.34949589 0.00125346\n",
      "180 0 1194.87118196 0.00147119\n",
      "181 4 1201.79642534 0.000982664\n",
      "182 2 1208.60559511 0.00110361\n",
      "183 10 1215.63514471 0.00088533\n",
      "184 33 1222.43802547 0.00111057\n",
      "185 169 1229.20492649 0.00115126\n",
      "186 169 1236.23487091 0.000884981\n",
      "187 169 1242.90432215 0.0012691\n",
      "188 169 1249.66899252 0.00115383\n",
      "189 169 1256.36994457 0.00122974\n",
      "190 7 1262.6939106 0.00179282\n",
      "191 24 1268.99300766 0.00183796\n",
      "192 4 1275.77151203 0.00113798\n",
      "193 2 1282.49462366 0.00120279\n",
      "194 10 1288.92994356 0.0016039\n",
      "195 102 1295.50958061 0.00138835\n",
      "196 5 1302.50169659 0.0009191\n",
      "197 3 1308.77182817 0.00189198\n",
      "198 13 1314.93984413 0.00209539\n",
      "199 169 1321.9789052 0.00087695\n",
      "200 0 1328.5779171 0.00136171\n",
      "201 24 1335.24270773 0.00127502\n",
      "202 55 1341.60088539 0.00173252\n",
      "203 2 1347.69461489 0.00225698\n",
      "204 169 1354.14734221 0.00157622\n",
      "205 169 1360.459795 0.00181358\n",
      "206 169 1366.87727499 0.00163277\n",
      "207 169 1373.3226862 0.00158779\n",
      "208 169 1379.93037271 0.00134995\n",
      "209 169 1386.43958807 0.00148965\n",
      "210 0 1392.92131662 0.00153116\n",
      "211 17 1399.28023195 0.00173124\n",
      "212 54 1405.57890797 0.00183874\n",
      "213 22 1412.62899446 0.000867334\n",
      "214 169 1418.85769892 0.00197201\n",
      "215 169 1425.54332685 0.00124873\n",
      "216 169 1431.97688675 0.00160672\n",
      "217 169 1438.49802303 0.001472\n",
      "218 169 1445.15743876 0.0012819\n",
      "219 169 1451.81570959 0.00128336\n",
      "220 46 1458.04080486 0.00197913\n",
      "221 10 1464.90970469 0.00103962\n",
      "222 35 1471.36044645 0.00157935\n",
      "223 33 1478.7243104 0.000633745\n",
      "224 27 1485.17853785 0.00157385\n",
      "225 169 1491.67517376 0.00150851\n",
      "226 169 1498.57236099 0.00101062\n",
      "227 169 1505.20398283 0.00131802\n",
      "228 169 1511.78253698 0.00138986\n",
      "229 169 1518.41023111 0.00132321\n",
      "230 12 1524.69013071 0.00187359\n",
      "231 169 1531.18599796 0.00150967\n",
      "232 169 1537.79288626 0.00135103\n",
      "233 169 1544.31618166 0.00146882\n",
      "234 169 1550.76484394 0.00158264\n",
      "235 169 1557.29236555 0.00146263\n",
      "236 169 1563.74386787 0.00157815\n",
      "237 169 1570.23395491 0.00151842\n",
      "238 169 1576.75630045 0.00147022\n",
      "239 169 1583.30227852 0.00143588\n",
      "240 51 1589.68203688 0.00169553\n",
      "241 0 1596.23004293 0.00143297\n",
      "242 22 1602.64867115 0.00163089\n",
      "243 3 1609.59286642 0.000964216\n",
      "244 60 1616.19922304 0.00135175\n",
      "245 169 1622.69578314 0.00150862\n",
      "246 169 1629.165627 0.00154947\n",
      "247 169 1635.70380688 0.00144712\n",
      "248 169 1642.31564617 0.00134436\n",
      "249 169 1648.88671494 0.0014003\n",
      "250 42 1655.50002766 0.00134238\n",
      "251 79 1662.27064514 0.00114699\n",
      "252 5 1668.83669043 0.00140735\n",
      "253 14 1675.38563681 0.00143162\n",
      "254 169 1681.63801003 0.00192588\n",
      "255 169 1688.00539398 0.00171664\n",
      "256 169 1694.58228159 0.00139218\n",
      "257 169 1701.22272873 0.00130644\n",
      "258 169 1707.90624523 0.00125137\n",
      "259 169 1714.52233934 0.00133865\n",
      "260 32 1721.02019835 0.00150666\n",
      "261 22 1727.6228652 0.00135674\n",
      "262 5 1734.60084581 0.000932184\n",
      "263 169 1741.20433283 0.00135563\n",
      "264 169 1747.91614008 0.00121646\n",
      "265 169 1754.66389418 0.00117351\n",
      "266 169 1761.11116505 0.00158484\n",
      "267 169 1767.68116283 0.0014018\n",
      "268 169 1774.17368555 0.00151472\n",
      "269 169 1780.76435328 0.00137312\n",
      "270 26 1787.68421221 0.000987969\n",
      "271 70 1794.6482625 0.00094526\n",
      "272 0 1800.93351936 0.00186358\n",
      "273 2 1807.35764837 0.00162195\n",
      "274 169 1813.72480297 0.00171704\n",
      "275 169 1820.09387875 0.00171374\n",
      "276 169 1826.80783033 0.00121386\n",
      "277 169 1833.2202549 0.00164104\n",
      "278 169 1839.7662015 0.00143592\n",
      "279 169 1846.31674767 0.00142933\n",
      "280 14 1852.86766338 0.00142881\n",
      "281 169 1859.32445192 0.00156983\n",
      "282 169 1865.91443872 0.00137406\n",
      "283 169 1872.38094234 0.00155465\n",
      "284 169 1878.84042263 0.00156561\n",
      "285 169 1885.33169556 0.00151662\n",
      "286 169 1891.80580282 0.00154288\n",
      "287 169 1898.28410482 0.00153642\n",
      "288 169 1904.83518457 0.00142857\n",
      "289 169 1911.36031437 0.00146613\n",
      "290 119 1918.13172817 0.00114607\n",
      "291 128 1924.74874878 0.00133741\n",
      "292 97 1931.37964153 0.00131899\n",
      "293 169 1937.91512632 0.00145103\n",
      "294 169 1944.37774611 0.0015607\n",
      "295 169 1950.97724771 0.00136105\n",
      "296 169 1957.48125076 0.00149743\n",
      "297 169 1964.09573126 0.00134081\n",
      "298 169 1970.66166925 0.0014075\n",
      "299 169 1977.20309305 0.00144243\n",
      "300 40 1983.78811884 0.00138089\n",
      "301 6 1990.38640881 0.0013627\n",
      "302 1 1996.48468065 0.00224675\n",
      "303 0 2003.9993577 0.000545026\n",
      "304 24 2010.38766956 0.00168109\n",
      "305 25 2016.68314743 0.00184463\n",
      "306 86 2023.36471844 0.00125381\n",
      "307 2 2030.18339968 0.00109316\n",
      "308 31 2036.24462271 0.00233155\n",
      "309 18 2042.96287775 0.00120865\n",
      "310 39 2049.42031097 0.00156882\n",
      "311 15 2055.8931756 0.00154479\n",
      "312 6 2062.49192905 0.00136207\n",
      "313 42 2069.21335983 0.00120481\n",
      "314 1 2075.5895896 0.00170153\n",
      "315 0 2082.34389019 0.00116585\n",
      "316 36 2089.35208607 0.000904439\n",
      "317 17 2096.00203133 0.00129409\n",
      "318 68 2102.4460988 0.00158993\n",
      "319 55 2109.04545879 0.00136124\n",
      "320 9 2115.51566362 0.00154891\n",
      "321 48 2122.0996623 0.00138231\n",
      "322 2 2128.64741945 0.00143333\n",
      "323 21 2135.01081896 0.0017235\n",
      "324 169 2141.88798523 0.00103106\n",
      "325 169 2148.54049349 0.00129078\n",
      "326 169 2155.14794302 0.00135027\n",
      "327 169 2161.94920444 0.00111237\n",
      "328 169 2168.64857531 0.00123169\n",
      "329 169 2175.26893854 0.00133295\n",
      "330 0 2181.82455587 0.00142211\n",
      "331 10 2188.35433292 0.00145933\n",
      "332 41 2194.87109423 0.00147845\n",
      "333 27 2201.86259413 0.000919666\n",
      "334 169 2208.45416975 0.00137188\n",
      "335 169 2214.8138752 0.00172988\n",
      "336 169 2221.30829334 0.00151185\n",
      "337 169 2227.83056355 0.00147033\n",
      "338 169 2234.37654066 0.00143588\n",
      "339 169 2240.82033253 0.00159036\n",
      "340 23 2247.67247391 0.00105719\n",
      "341 22 2254.06437445 0.00167507\n",
      "342 14 2260.57193279 0.00149212\n",
      "343 169 2267.26617146 0.00123802\n",
      "344 169 2273.77016115 0.00149745\n",
      "345 169 2280.24472284 0.00154217\n",
      "346 169 2286.72442722 0.00153426\n",
      "347 169 2293.16482735 0.00159577\n",
      "348 169 2299.59146166 0.00161789\n",
      "349 169 2306.17609501 0.00138143\n",
      "350 39 2312.57530308 0.00166287\n",
      "351 15 2318.89162302 0.00180658\n",
      "352 24 2325.16157055 0.00189233\n",
      "353 48 2331.89294052 0.0011929\n",
      "354 4 2339.13814449 0.000713589\n",
      "355 46 2345.88541794 0.00117408\n",
      "356 2 2352.30174828 0.00163464\n",
      "357 64 2358.90227222 0.00135966\n",
      "358 71 2365.73921347 0.00107338\n",
      "359 92 2372.3737545 0.00131418\n",
      "360 10 2379.26622486 0.0010154\n",
      "361 13 2386.31690979 0.000866815\n",
      "362 169 2392.90913105 0.00137099\n",
      "363 169 2399.47614384 0.00140599\n",
      "364 169 2405.98884487 0.00148446\n",
      "365 169 2412.56300879 0.00139597\n",
      "366 169 2419.1475563 0.00138155\n",
      "367 169 2425.75416517 0.00135141\n",
      "368 169 2432.37749147 0.001329\n",
      "369 169 2438.93451643 0.0014201\n",
      "370 37 2445.69518375 0.00115846\n",
      "371 5 2452.19341183 0.00150611\n",
      "372 16 2458.78228521 0.00137559\n",
      "373 13 2464.851264 0.00231353\n",
      "374 169 2471.39247417 0.00144274\n",
      "375 169 2477.94879246 0.00142111\n",
      "376 169 2484.42954731 0.00153265\n",
      "377 169 2490.9452877 0.00147996\n",
      "378 169 2497.44111586 0.00150972\n",
      "379 169 2503.91965532 0.00153605\n",
      "380 1 2510.65429258 0.00118901\n",
      "381 58 2517.06685305 0.00164082\n",
      "382 27 2523.64252663 0.00139387\n",
      "383 65 2529.85126829 0.00201177\n",
      "384 169 2536.59697628 0.00117592\n",
      "385 169 2543.36329651 0.00115193\n",
      "386 169 2549.99326468 0.00132021\n",
      "387 169 2556.69960356 0.00122313\n",
      "388 169 2563.671597 0.000937782\n",
      "389 169 2570.49041843 0.00109301\n",
      "390 1 2576.95663977 0.00155509\n",
      "391 0 2583.34339523 0.00168371\n",
      "392 17 2590.13408756 0.00112419\n",
      "393 18 2596.20453835 0.00231013\n",
      "394 47 2603.09954548 0.00101283\n",
      "395 37 2609.87457037 0.00114194\n",
      "396 41 2616.76720476 0.00101524\n",
      "397 169 2623.20185947 0.00160496\n",
      "398 169 2629.67569351 0.0015433\n",
      "399 169 2636.14199448 0.00155497\n",
      "400 25 2642.79978895 0.00128398\n",
      "401 4 2649.04718685 0.00193548\n",
      "402 17 2655.36931992 0.00179611\n",
      "403 2 2661.81120491 0.0015934\n",
      "404 3 2668.5038147 0.00124004\n",
      "405 108 2675.54674053 0.000873567\n",
      "406 169 2682.10529375 0.00141794\n",
      "407 169 2688.4880991 0.00169037\n",
      "408 169 2695.14831448 0.00128087\n",
      "409 169 2701.71192026 0.00141079\n",
      "410 0 2708.10856676 0.00166714\n",
      "411 25 2714.76724195 0.00128285\n",
      "412 4 2720.91668892 0.00213466\n",
      "413 54 2727.39022207 0.00154376\n",
      "414 90 2733.41590023 0.00241591\n",
      "415 46 2739.51416063 0.00224677\n",
      "416 10 2745.87317657 0.00173107\n",
      "417 3 2752.1783309 0.00182686\n",
      "418 169 2758.99291849 0.00109765\n",
      "419 169 2765.72523832 0.00119177\n",
      "420 130 2772.13609743 0.00164361\n",
      "421 1 2779.06235313 0.00098167\n",
      "422 0 2785.66722441 0.00135376\n",
      "423 36 2792.83738422 0.0007692\n",
      "424 54 2799.59669304 0.00116003\n",
      "425 3 2806.23904514 0.00130396\n",
      "426 12 2813.03484774 0.00111846\n",
      "427 27 2819.78536129 0.00117028\n",
      "428 169 2826.11515665 0.0017824\n",
      "429 169 2832.53937578 0.0016218\n",
      "430 13 2839.46052599 0.000986694\n",
      "431 169 2845.81775236 0.00173417\n",
      "432 169 2852.39305449 0.00139438\n",
      "433 169 2859.02934122 0.00131189\n",
      "434 169 2865.61545849 0.00137939\n",
      "435 169 2872.18599939 0.00140104\n",
      "436 169 2878.74769449 0.00141349\n",
      "437 169 2885.34945202 0.00135798\n",
      "438 169 2891.97712517 0.00132324\n",
      "439 169 2898.58346653 0.00135177\n",
      "440 31 2905.17060566 0.00137798\n",
      "441 21 2911.59526587 0.00162108\n",
      "442 37 2918.22750473 0.00131721\n",
      "443 28 2924.88909292 0.00127911\n",
      "444 169 2931.12462616 0.00195858\n",
      "445 169 2937.65400839 0.00145991\n",
      "446 169 2944.34087849 0.00124718\n",
      "447 169 2950.89220905 0.00142821\n",
      "448 169 2957.3484683 0.00157066\n",
      "449 169 2963.85779333 0.00148949\n",
      "450 25 2970.41551113 0.00141912\n",
      "451 5 2977.18028688 0.00115371\n",
      "452 169 2983.81670713 0.00131171\n",
      "453 169 2990.56728649 0.0011702\n",
      "454 169 2997.23203993 0.00127507\n",
      "455 169 3003.80125189 0.0014029\n",
      "456 169 3010.33448696 0.00145429\n",
      "457 169 3016.81412411 0.00153437\n",
      "458 169 3023.39991474 0.00137984\n",
      "459 169 3029.99766636 0.00136343\n",
      "460 46 3036.24884987 0.00192817\n",
      "461 21 3043.32584143 0.000844309\n",
      "462 60 3049.32116365 0.00249037\n",
      "463 169 3056.02433681 0.00122701\n",
      "464 169 3062.81710339 0.00112186\n",
      "465 169 3069.66334486 0.00106345\n",
      "466 169 3076.19677114 0.00145402\n",
      "467 169 3082.7997632 0.0013563\n",
      "468 169 3089.38134575 0.00138565\n",
      "469 169 3095.97318411 0.00137152\n",
      "470 6 3102.24406433 0.00189056\n",
      "471 1 3108.93545485 0.00124156\n",
      "472 29 3115.39599037 0.00156396\n",
      "473 83 3122.08616686 0.00124306\n",
      "474 19 3128.96317148 0.00103123\n",
      "475 169 3135.4078908 0.00158889\n",
      "476 169 3141.91620111 0.001491\n",
      "477 169 3148.53088713 0.00134054\n",
      "478 169 3155.20385742 0.00126464\n",
      "479 169 3161.74649382 0.00144069\n",
      "480 39 3168.13978672 0.00167274\n",
      "481 99 3174.93744469 0.00111639\n",
      "482 3 3181.295434 0.00173285\n",
      "483 169 3187.78428841 0.00152029\n",
      "484 169 3194.175313 0.00167654\n",
      "485 169 3200.61984015 0.0015892\n",
      "486 169 3207.01658106 0.00166698\n",
      "487 169 3213.50408268 0.00152235\n",
      "488 169 3220.02016735 0.00147945\n",
      "489 169 3226.48938847 0.00155043\n",
      "490 40 3233.18800259 0.00123262\n",
      "491 1 3239.3660121 0.00207455\n",
      "492 0 3246.38847637 0.000891626\n",
      "493 46 3253.07774162 0.0012442\n",
      "494 13 3259.77439737 0.00123504\n",
      "495 169 3266.220963 0.00158596\n",
      "496 169 3272.83201265 0.00134542\n",
      "497 169 3279.41986132 0.001377\n",
      "498 169 3286.15639019 0.00118676\n",
      "499 169 3292.72373438 0.00140553\n",
      "500 15 3299.42508554 0.00122925\n",
      "501 2 3306.47310972 0.000869124\n",
      "502 10 3313.25458002 0.00113461\n",
      "503 5 3320.12402725 0.00103905\n",
      "504 16 3326.53261423 0.00164735\n",
      "505 13 3333.28044224 0.00117343\n",
      "506 169 3339.64129496 0.00172789\n",
      "507 169 3346.14764977 0.00149392\n",
      "508 169 3352.62658548 0.00153544\n",
      "509 169 3359.12958431 0.00149894\n",
      "510 0 3365.68056297 0.00142872\n",
      "511 54 3372.19492435 0.001482\n",
      "512 10 3378.74045229 0.00143653\n",
      "513 169 3385.15411043 0.00163902\n",
      "514 169 3391.52752924 0.00170632\n",
      "515 169 3398.0284543 0.00150205\n",
      "516 169 3404.68638659 0.0012838\n",
      "517 169 3411.21372652 0.00146289\n",
      "518 169 3417.84524202 0.00131816\n",
      "519 169 3424.49772835 0.00129081\n",
      "520 4 3431.08795452 0.00137373\n",
      "521 46 3437.92207003 0.00107642\n",
      "522 5 3444.18520927 0.00190526\n",
      "523 169 3450.96832085 0.00113274\n",
      "524 169 3457.73857689 0.0011474\n",
      "525 169 3464.44626808 0.00122148\n",
      "526 169 3471.14924002 0.00122726\n",
      "527 169 3477.85046577 0.0012294\n",
      "528 169 3484.39056253 0.00144435\n",
      "529 169 3490.95950031 0.00140329\n",
      "530 11 3497.70098305 0.00118089\n",
      "531 6 3504.26504278 0.00141015\n",
      "532 169 3511.18531752 0.000987559\n",
      "533 169 3517.89490795 0.00121916\n",
      "534 169 3524.60962152 0.00121293\n",
      "535 169 3531.23397636 0.00132764\n",
      "536 169 3537.85785913 0.00132826\n",
      "537 169 3544.59472275 0.00118636\n",
      "538 169 3551.21503639 0.00133301\n",
      "539 169 3557.78225422 0.0014057\n",
      "540 1 3564.13929081 0.0017345\n",
      "541 0 3571.0740571 0.000973351\n",
      "542 36 3578.18600035 0.000815309\n",
      "543 48 3585.21097755 0.000889388\n",
      "544 4 3592.1612978 0.000958328\n",
      "545 17 3598.65936279 0.00150635\n",
      "546 18 3605.40178156 0.00117979\n",
      "547 5 3611.86095953 0.00156608\n",
      "548 3 3618.48596525 0.00132677\n",
      "549 35 3624.94471836 0.00156675\n",
      "550 25 3631.74360657 0.00111501\n",
      "551 4 3638.29728079 0.00142487\n",
      "552 17 3644.78788996 0.00151762\n",
      "553 2 3652.06304455 0.000692533\n",
      "554 22 3658.69848299 0.001313\n",
      "555 5 3665.09798765 0.00166238\n",
      "556 33 3671.78109884 0.00125188\n",
      "557 13 3678.6972785 0.000991611\n",
      "558 169 3685.35927486 0.00127859\n",
      "559 169 3691.88268137 0.00146866\n",
      "560 11 3698.47967529 0.00136446\n",
      "561 32 3704.69164038 0.00200529\n",
      "562 77 3710.77654552 0.00227698\n",
      "563 66 3717.70876884 0.000975829\n",
      "564 21 3724.42150831 0.00121533\n",
      "565 37 3731.30414867 0.00102543\n",
      "566 63 3737.40373659 0.00224379\n",
      "567 34 3743.98160839 0.00139081\n",
      "568 58 3750.7882247 0.00110643\n",
      "569 169 3757.3911767 0.00135636\n",
      "570 57 3763.9054389 0.00148215\n",
      "571 40 3770.47474909 0.00140276\n",
      "572 1 3776.6781702 0.0020225\n",
      "573 0 3783.84263563 0.000773592\n",
      "574 38 3790.61649036 0.00114328\n",
      "575 2 3797.23659039 0.0013333\n",
      "576 104 3803.79495001 0.00141821\n",
      "577 5 3810.36272764 0.00140492\n",
      "578 3 3817.28943539 0.000981226\n",
      "579 60 3824.24857998 0.000949909\n",
      "580 35 3830.51439905 0.00190016\n",
      "581 169 3837.02853012 0.00148234\n",
      "582 169 3843.48600388 0.00156875\n",
      "583 169 3850.13927412 0.0012898\n",
      "584 169 3856.70062256 0.00141398\n",
      "585 169 3863.38248444 0.00125344\n",
      "586 169 3870.03086185 0.00129612\n",
      "587 169 3876.62166023 0.00137294\n",
      "588 169 3883.17764568 0.00142158\n",
      "589 169 3889.74687719 0.00140288\n",
      "590 29 3896.6400218 0.00101472\n",
      "591 10 3903.0974102 0.00156889\n",
      "592 169 3909.7833128 0.00124839\n",
      "593 169 3916.50925779 0.00119939\n",
      "594 169 3923.03571939 0.00146418\n",
      "595 169 3929.65424109 0.0013354\n",
      "596 169 3936.21779776 0.00141086\n",
      "597 169 3942.69736767 0.00153447\n",
      "598 169 3949.23652124 0.00144571\n",
      "599 169 3955.82971668 0.00136966\n",
      "600 35 3962.15843105 0.00178433\n",
      "601 43 3968.82583952 0.00127169\n",
      "602 49 3975.91005659 0.000838231\n",
      "603 169 3982.64298105 0.00119104\n",
      "604 169 3989.26028156 0.00133704\n",
      "605 169 3995.77673769 0.0014789\n",
      "606 169 4002.50558949 0.00119591\n",
      "607 169 4009.0781374 0.00139823\n",
      "608 169 4015.72532034 0.00129767\n",
      "609 169 4022.28693008 0.00141361\n",
      "610 39 4028.76279449 0.00154017\n",
      "611 11 4035.70782709 0.000963409\n",
      "612 6 4042.23874092 0.00145767\n",
      "613 1 4048.49753332 0.00191355\n",
      "614 32 4055.08319855 0.00138001\n",
      "615 119 4062.08007574 0.000914734\n",
      "616 19 4068.64008284 0.00141588\n",
      "617 56 4075.41017675 0.00114759\n",
      "618 35 4082.41201258 0.000910209\n",
      "619 169 4088.95875931 0.00143478\n",
      "620 70 4095.59834051 0.00130757\n",
      "621 1 4102.29905367 0.00123003\n",
      "622 36 4109.19980478 0.00100703\n",
      "623 37 4115.55809689 0.00173232\n",
      "624 8 4121.86666727 0.00182063\n",
      "625 169 4128.46911478 0.00135704\n",
      "626 169 4135.21355247 0.00117741\n",
      "627 169 4141.8214612 0.00134965\n",
      "628 169 4148.69395113 0.00103589\n",
      "629 169 4155.39988613 0.00122363\n",
      "630 7 4161.97534227 0.00139417\n",
      "631 1 4168.61298418 0.00131011\n",
      "632 0 4175.55130529 0.000969896\n",
      "633 46 4182.48863316 0.00097086\n",
      "634 2 4188.8051877 0.00180616\n",
      "635 59 4195.29627275 0.0015169\n",
      "636 27 4201.74438047 0.00158352\n",
      "637 13 4208.37650204 0.00131737\n",
      "638 169 4215.45079613 0.00084659\n",
      "639 169 4222.29722166 0.00106325\n",
      "640 24 4228.80312395 0.00149459\n",
      "641 2 4235.54120159 0.00118492\n",
      "642 62 4242.27041197 0.00119548\n",
      "643 3 4248.51383305 0.0019432\n",
      "644 16 4255.02255821 0.00149038\n",
      "645 33 4261.02948618 0.00246164\n",
      "646 169 4267.04426813 0.00244238\n",
      "647 169 4273.46666622 0.00162476\n",
      "648 169 4279.91096067 0.00158957\n",
      "649 169 4286.38459349 0.00154361\n",
      "650 1 4293.05335569 0.00126997\n",
      "651 19 4299.84463263 0.00112353\n",
      "652 104 4306.68764639 0.00106688\n",
      "653 123 4313.00986099 0.00179596\n",
      "654 3 4319.48232126 0.00154542\n",
      "655 65 4326.28090763 0.00111535\n",
      "656 169 4332.63497305 0.00173966\n",
      "657 169 4339.02169991 0.00168376\n",
      "658 169 4345.46412134 0.00159255\n",
      "659 169 4352.06640148 0.00135727\n",
      "660 30 4358.43478489 0.00171493\n",
      "661 26 4364.92725801 0.0015148\n",
      "662 39 4371.58640814 0.00128224\n",
      "663 11 4378.40068293 0.00109799\n",
      "664 57 4384.70740461 0.001824\n",
      "665 6 4390.85086966 0.00214747\n",
      "666 0 4397.61977816 0.00114895\n",
      "667 24 4404.62354565 0.000908453\n",
      "668 17 4410.32690477 0.00333475\n",
      "669 66 4416.63159847 0.00182771\n",
      "670 11 4423.32410002 0.00124018\n",
      "671 1 4429.81507397 0.00151707\n",
      "672 24 4436.30974102 0.00151148\n",
      "673 4 4443.13660479 0.00108425\n",
      "674 83 4449.97993612 0.00106654\n",
      "675 19 4456.61487436 0.00131366\n",
      "676 2 4462.6402545 0.00241663\n",
      "677 121 4469.12510347 0.00152639\n",
      "678 78 4475.82686186 0.00122875\n",
      "679 169 4482.76799154 0.000967176\n",
      "680 5 4489.27468967 0.0014934\n",
      "681 3 4496.10417747 0.00108141\n",
      "682 12 4502.91225338 0.00110482\n",
      "683 169 4509.36564445 0.00157517\n",
      "684 169 4515.85944462 0.00151279\n",
      "685 169 4522.29383087 0.00160539\n",
      "686 169 4528.91313887 0.00133435\n",
      "687 169 4535.42362785 0.00148775\n",
      "688 169 4541.89043093 0.00155419\n",
      "689 169 4548.47448874 0.00138223\n",
      "690 7 4555.26348686 0.0011261\n",
      "691 1 4561.83968067 0.00139314\n",
      "692 107 4568.60957909 0.00114781\n",
      "693 8 4574.72397327 0.00221081\n",
      "694 169 4581.57433558 0.00105907\n",
      "695 169 4588.0665617 0.00151517\n",
      "696 169 4594.65991402 0.00136944\n",
      "697 169 4601.10536194 0.00158773\n",
      "698 169 4607.60347223 0.00150628\n",
      "699 169 4614.18985128 0.00137902\n"
     ]
    }
   ],
   "source": [
    "b=0\n",
    "for i,j in enumerate(qa):\n",
    "    b += -1*np.log(result[i][j])\n",
    "    print(i,j,b,result[i][j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.533333333333333"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "980/150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
