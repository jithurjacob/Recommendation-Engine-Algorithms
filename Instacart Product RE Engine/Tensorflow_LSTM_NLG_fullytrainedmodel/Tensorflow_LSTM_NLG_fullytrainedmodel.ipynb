{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import tensorflow as tf\n",
    "import itertools\n",
    "import operator\n",
    "import numpy as np\n",
    "import nltk\n",
    "import sys\n",
    "from datetime import datetime\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vocabulary_size = 8000\n",
    "unknown_token = \"UNKNOWN_TOKEN\"\n",
    "sentence_start_token = \"SENTENCE_START\"\n",
    "sentence_end_token = \"SENTENCE_END\"\n",
    "\n",
    "with open('data/reddit-comments-2015-08.csv', 'r',encoding='utf-8') as f:\n",
    "    reader = csv.reader(f)\n",
    "    next(reader)\n",
    "    #reader is a list of [[sen123],[sen456],..]\n",
    "    #eaxh x, ie., x[0] is sen123\n",
    "    #now sen123 is sent_tokenized to give [sen1,sen2,sen3]\n",
    "    #*[nltk.sent_tokenize(x[0].lower()) for x in reader], at end you have the below list of sentences. \n",
    "    # iterchain will combine the sentences in [[sen1,sen2,sen3],[sen4,sen5,sen6]], this is the input to iterchain\n",
    "    sentences = itertools.chain(*[nltk.sent_tokenize(x[0].lower()) for x in reader])\n",
    "    #output after iterchain is [sen1,sen2,sen3,sen4,sen5,sen5]\n",
    "    #print list(sentences)\n",
    "    sentences = [\"%s %s %s\" % (sentence_start_token, x, sentence_end_token) for x in sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tokenized_sentences = [nltk.word_tokenize(sent) for sent in sentences]\n",
    "print(tokenized_sentences[0], len(tokenized_sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#import pickle\n",
    "#with open('data.txt', 'wb') as f:\n",
    "#    pickle.dump(tokenized_sentences, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('data.txt', 'rb') as fp:\n",
    "    tokenized_sentences = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open ('words.txt', 'rb') as fp:\n",
    "    wordlist = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('embeddings.txt','rb') as fp:\n",
    "    embeddings = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "word = wordlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.00781539, -0.96002924,  0.70458364,  0.90016514, -0.25974044,\n",
       "       -0.82872403,  0.32521391,  1.23866975, -0.2158218 , -0.58259046,\n",
       "        0.56482399, -0.59560162,  0.07931113, -0.35424623,  0.10623121,\n",
       "       -0.48939413, -0.4324761 ,  0.6599136 , -0.06735279, -0.42809385,\n",
       "       -0.11427003,  0.08903392,  0.16611898, -0.15760079,  0.20780087,\n",
       "        0.18664664,  0.11466923, -0.15877327,  0.14732024,  0.04144473,\n",
       "       -0.97858113, -0.15506968, -0.39343002,  0.34112266, -0.52571779,\n",
       "       -1.01909554,  0.63601589, -0.08794332,  0.13931367, -0.10933137,\n",
       "        0.89080191, -0.11247748, -0.09380047, -0.62214637,  0.22348887,\n",
       "       -0.45586807, -0.16441527, -0.12084212,  0.75253934,  0.74877995,\n",
       "       -0.24148768,  0.10676587, -0.34654984, -0.84981006, -0.05637517,\n",
       "        1.17814636,  0.38551748,  0.75880963,  0.72178942,  0.31493187,\n",
       "        0.1618239 , -0.6417715 , -0.83980197, -0.14380476, -0.45894837,\n",
       "        0.07221667, -0.31993574, -0.55760813, -0.599801  ,  0.11194099,\n",
       "        1.00358415,  0.54806286, -0.30858529,  0.37481481,  0.34448326,\n",
       "       -0.8137272 , -0.51297504,  0.39936188, -1.0565021 ,  0.16305831,\n",
       "       -1.20940566,  0.14365013, -0.61821836,  0.52856082, -0.45544213,\n",
       "       -0.72265315,  1.12416959, -0.26147988, -0.00666758,  0.00362897,\n",
       "        1.07353652, -0.58118665,  0.61049652,  0.07274828,  0.35694921,\n",
       "       -0.31900543, -0.46477979, -0.36628321, -0.96166492, -0.47912759,\n",
       "        0.60474402,  0.58580613, -0.12581345, -1.0250783 , -1.10476375,\n",
       "       -0.81256229, -0.72335196,  0.78244817,  0.89309579,  0.27557015,\n",
       "       -0.2531932 , -0.03712197, -0.8514694 , -0.29584187,  0.29076549,\n",
       "       -0.14546758,  0.28688267,  0.49697506,  0.81076795,  0.38703948,\n",
       "       -0.66069883, -0.48266238, -0.19363672, -0.3519423 ,  0.45734531,\n",
       "       -0.35777619, -1.3206625 ,  0.15660359, -0.37594289,  0.68705773,\n",
       "       -0.29683325,  1.30174315, -0.39993265, -0.00715323, -0.67083168,\n",
       "       -0.49708268,  0.85481304, -0.00808564,  0.52181745, -0.33925125,\n",
       "        0.46601802, -0.14421904, -1.26654565, -0.20530927,  0.09103449,\n",
       "       -0.44381511,  0.31815451,  0.1292901 , -0.32063431, -0.34813908,\n",
       "       -0.42060664, -0.18777931,  0.55002874, -0.68628001, -0.10058621,\n",
       "       -0.73297274,  0.36100012,  0.36736268, -0.53998339,  0.28036061,\n",
       "        0.82091355,  0.42055571, -0.39396447, -0.35039064, -0.80328894,\n",
       "       -0.39691707, -1.1978929 , -0.11817022,  0.29158661, -0.32667333,\n",
       "        0.87448615,  0.59187728, -0.54242724, -1.01908803,  0.0602721 ,\n",
       "        0.48212239,  0.29169846,  0.93258607,  0.09111452,  0.66899812,\n",
       "        0.98944235,  0.32075292,  0.19012326,  0.93492603, -0.36534941,\n",
       "        0.32452595,  0.63568711, -0.40081188,  0.84576654,  0.87991744,\n",
       "       -0.60764635,  1.04719329, -0.53924084, -0.6397121 ,  0.19944552,\n",
       "        0.37289429,  0.40479863,  0.68648666,  0.49412674,  0.3008498 ], dtype=float32)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings[2761]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "word_to_index = dict([(w,i) for i,w in enumerate(wordlist)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'wife': 1080,\n",
       " 'eats': 7109,\n",
       " 'laser': 4616,\n",
       " 'strive': 7418,\n",
       " 'mentioning': 4027,\n",
       " '**|**': 821,\n",
       " 'reminds': 3201,\n",
       " 'drafted': 7650,\n",
       " 'fox': 3317,\n",
       " 'catfish': 7181,\n",
       " 'typically': 1370,\n",
       " 'als': 6338,\n",
       " 'suggestions': 2129,\n",
       " 'lands': 4800,\n",
       " 'draws': 6113,\n",
       " 'regulation': 6051,\n",
       " 'reader': 5279,\n",
       " 'succeed': 5134,\n",
       " 'surprised': 1206,\n",
       " 'unlocked': 5151,\n",
       " 'guarantee': 3245,\n",
       " 'ps4': 3045,\n",
       " 'roller': 7548,\n",
       " 'some': 72,\n",
       " 'firmly': 5350,\n",
       " 'grams': 5728,\n",
       " 'alternative': 2514,\n",
       " 'claiming': 2450,\n",
       " '_____': 7475,\n",
       " 'gained': 2592,\n",
       " 'timer': 3367,\n",
       " '^^^=': 6825,\n",
       " 'starters': 4587,\n",
       " 'wrath': 3067,\n",
       " 'headaches': 7351,\n",
       " 'designers': 6544,\n",
       " 'gio': 7838,\n",
       " 'gifs': 7704,\n",
       " 'noting': 7599,\n",
       " 'disappeared': 7680,\n",
       " 'hour': 836,\n",
       " 'conservatives': 4540,\n",
       " 'tor': 6555,\n",
       " 'ar': 7651,\n",
       " 'scripts': 7076,\n",
       " 'require': 1267,\n",
       " 'needed': 592,\n",
       " 'drinks': 3003,\n",
       " '*will*': 2887,\n",
       " 'divine': 5355,\n",
       " 'clearing': 7789,\n",
       " 'dragons': 3981,\n",
       " 'parent': 2610,\n",
       " 'popularity': 5557,\n",
       " 'eternity': 7221,\n",
       " 'rider': 6861,\n",
       " 'entertaining': 4340,\n",
       " 'ways': 750,\n",
       " 'database': 3383,\n",
       " 'leather': 6010,\n",
       " 'labs': 7601,\n",
       " 'coworkers': 6636,\n",
       " '48': 6758,\n",
       " 'legend': 6817,\n",
       " 'clean': 1041,\n",
       " 'neat': 3319,\n",
       " 'subject=can': 7689,\n",
       " 'argue': 1273,\n",
       " \"'m\": 67,\n",
       " 'mistake': 1159,\n",
       " 'android': 3103,\n",
       " 'civilians': 5178,\n",
       " 'ear': 3930,\n",
       " 'alphabet': 7727,\n",
       " '4-5': 6261,\n",
       " 'cite': 6822,\n",
       " 'ab': 7289,\n",
       " 'intention': 3759,\n",
       " 'living': 683,\n",
       " 'motor': 3894,\n",
       " 'divorce': 3282,\n",
       " 'common': 635,\n",
       " 'asians': 7706,\n",
       " '^^^if': 5344,\n",
       " 'iran': 6056,\n",
       " 'unhealthy': 3899,\n",
       " 'atomic': 5979,\n",
       " 'hallway': 7435,\n",
       " 'occasional': 4523,\n",
       " 'tax': 1456,\n",
       " 'thank': 431,\n",
       " 'table': 1442,\n",
       " 'servers': 2001,\n",
       " 'carries': 3883,\n",
       " 'refused': 3742,\n",
       " 'fiscal': 7160,\n",
       " 'double': 974,\n",
       " 'crazy': 787,\n",
       " 'pole': 7208,\n",
       " 'wikipedia': 4289,\n",
       " 'greater': 2267,\n",
       " 'reduced': 2970,\n",
       " 'speeds': 6705,\n",
       " '&': 56,\n",
       " 'passive': 1903,\n",
       " 'maker': 7534,\n",
       " '“i': 7276,\n",
       " 'perk': 5923,\n",
       " 'heroic': 3956,\n",
       " 'counseling': 4516,\n",
       " 'intense': 3608,\n",
       " 'martin': 3499,\n",
       " '/r/totesmessenger': 6166,\n",
       " 'processed': 5269,\n",
       " 'crank': 7856,\n",
       " 'om': 4428,\n",
       " 'hoping': 1204,\n",
       " 'breast': 4507,\n",
       " 'darker': 6239,\n",
       " 'gigabyte': 5533,\n",
       " 'mike': 2995,\n",
       " 'assumed': 2631,\n",
       " 'disappointment': 7246,\n",
       " 'well': 117,\n",
       " 'emperor': 5808,\n",
       " 'useful': 993,\n",
       " 'marketing': 2496,\n",
       " 'ought': 5373,\n",
       " 'hence': 2552,\n",
       " 'link': 384,\n",
       " 'wreck': 4192,\n",
       " 'pro': 1498,\n",
       " 'also': 94,\n",
       " 'shiny': 5632,\n",
       " 'unaware': 6367,\n",
       " 'ser': 7648,\n",
       " 'fixed': 1392,\n",
       " 'regulations': 4797,\n",
       " 'enemies': 1834,\n",
       " 'stories': 1059,\n",
       " 'lion': 6858,\n",
       " 'catholic': 3384,\n",
       " 'firearm': 2342,\n",
       " 'unaltered': 3315,\n",
       " 'crowd': 2010,\n",
       " 'recommend': 740,\n",
       " 'landlord': 4412,\n",
       " 'solar': 4492,\n",
       " 'asking': 523,\n",
       " 'assassin': 7465,\n",
       " 'report': 807,\n",
       " 'neighborhood': 2914,\n",
       " 'companies': 1127,\n",
       " 'critique': 7040,\n",
       " 'pocket': 3585,\n",
       " 'plot': 2124,\n",
       " 'slim': 5726,\n",
       " 'arent': 4426,\n",
       " 'soup': 4570,\n",
       " 'utter': 4404,\n",
       " 'settlement': 6390,\n",
       " 'downtown': 4173,\n",
       " 'rolls': 3366,\n",
       " '^^^fetchable**': 6887,\n",
       " 'very': 126,\n",
       " 'summons': 5911,\n",
       " 'restore': 5624,\n",
       " 'fruit': 3834,\n",
       " 'diagnosis': 6755,\n",
       " '22': 2776,\n",
       " 'live': 319,\n",
       " 'throne': 6282,\n",
       " 'ssr': 7489,\n",
       " \"''\": 41,\n",
       " '//www.p0ody-files.com/ff_to_ebook/mobile/makeepub.php': 6656,\n",
       " 'imagine': 672,\n",
       " 'gtx': 2082,\n",
       " 'alien': 3248,\n",
       " 'value': 638,\n",
       " 'insane': 1664,\n",
       " 'pumped': 6337,\n",
       " 'stones': 4170,\n",
       " 'funding': 2964,\n",
       " 'communist': 6326,\n",
       " 'wrestling': 4565,\n",
       " 'wondering': 1867,\n",
       " 'add': 437,\n",
       " 't=all': 3592,\n",
       " 'temporary': 2490,\n",
       " 'lately': 2634,\n",
       " '3f': 5667,\n",
       " 'shovel': 6125,\n",
       " 'consequences': 3006,\n",
       " 'queens': 5537,\n",
       " 'shots': 1714,\n",
       " 'never': 155,\n",
       " 'view': 806,\n",
       " 'stronger': 1745,\n",
       " 'pray': 3180,\n",
       " '**memory**': 7408,\n",
       " 'dishonest': 7835,\n",
       " 'expecting': 2103,\n",
       " 'painted': 6653,\n",
       " 'stranger': 3617,\n",
       " 'lil': 6549,\n",
       " 'mapping': 7163,\n",
       " 'lan': 7675,\n",
       " 'sport': 1768,\n",
       " 'moral': 2246,\n",
       " 'supporting': 2048,\n",
       " 'deeper': 3884,\n",
       " 'shown': 1629,\n",
       " 'på': 3758,\n",
       " 'sucking': 5719,\n",
       " 'calories': 2022,\n",
       " 'kik': 7537,\n",
       " 'woman': 725,\n",
       " 'blm': 6963,\n",
       " 'wants': 570,\n",
       " 'guesses': 5498,\n",
       " 'podcast': 4942,\n",
       " 'UNKNOWN_TOKEN': 0,\n",
       " '^^^gatherer': 6978,\n",
       " 'russians': 6596,\n",
       " 'physical': 1026,\n",
       " 'comedy': 3793,\n",
       " 'hahaha': 5189,\n",
       " 'terrain': 4808,\n",
       " 'jewelry': 7665,\n",
       " 'logs': 5454,\n",
       " 'sort': 421,\n",
       " 'conversion': 5757,\n",
       " 'perception': 3567,\n",
       " 'theyre': 6195,\n",
       " 'plain': 2172,\n",
       " 'adequate': 4358,\n",
       " 'https': 118,\n",
       " 'wages': 3375,\n",
       " 'component': 4793,\n",
       " 'prominent': 5118,\n",
       " 'every': 173,\n",
       " 'seattle': 4167,\n",
       " 'manual': 3048,\n",
       " 'negate': 7583,\n",
       " 'busy': 2076,\n",
       " 'intelligence': 4047,\n",
       " 'max': 1112,\n",
       " 'entering': 5083,\n",
       " 'storm': 2633,\n",
       " 'stomach': 4512,\n",
       " 'freezing': 6719,\n",
       " 'senses': 7860,\n",
       " 'shares': 5169,\n",
       " 'notable': 6406,\n",
       " 'transfers': 5771,\n",
       " 'preventing': 6408,\n",
       " 'foundations': 7123,\n",
       " 'can': 48,\n",
       " 'favor': 2293,\n",
       " 'landing': 4266,\n",
       " 'puzzle': 6156,\n",
       " '/s': 3446,\n",
       " '2016': 3195,\n",
       " 'northern': 3804,\n",
       " 'angles': 6003,\n",
       " 'alliance': 4680,\n",
       " 'graphics': 2237,\n",
       " 'effort': 1063,\n",
       " 'firearms': 1730,\n",
       " 'operations': 4746,\n",
       " 'commenting': 5137,\n",
       " 'chrono': 5753,\n",
       " 'bail': 5230,\n",
       " 'black': 420,\n",
       " 'synergy': 6700,\n",
       " 'summer': 1348,\n",
       " '^^': 1576,\n",
       " 'hm': 7383,\n",
       " 'ineffective': 7387,\n",
       " 'fanbase': 7803,\n",
       " 'rushed': 6426,\n",
       " 'latter': 3466,\n",
       " 'buttons': 4065,\n",
       " 'connections': 3391,\n",
       " 'survivor': 6733,\n",
       " 'louder': 5716,\n",
       " 'neither': 1413,\n",
       " 'cooperation': 4269,\n",
       " 'ethics': 3965,\n",
       " 'carefully': 4083,\n",
       " 'protected': 2568,\n",
       " 'dwellings': 3044,\n",
       " 'before': 159,\n",
       " 'align': 6220,\n",
       " 'ranked': 1823,\n",
       " 'tragedy': 7616,\n",
       " 'primary': 1826,\n",
       " 'cream': 3122,\n",
       " 'dealers': 7094,\n",
       " 'insecure': 4872,\n",
       " 'paragraph': 4086,\n",
       " 'prone': 5641,\n",
       " 'service': 814,\n",
       " 'enforced': 7010,\n",
       " 'crate': 5023,\n",
       " 'gameplay': 1839,\n",
       " 'customers': 2110,\n",
       " 'elementary': 6792,\n",
       " 'quoted': 4787,\n",
       " 'billion': 3801,\n",
       " 'kernel': 6244,\n",
       " 'af': 5912,\n",
       " 'opportunities': 3557,\n",
       " 'egg': 3646,\n",
       " 'calorie': 6501,\n",
       " 'exception': 2154,\n",
       " 'sand': 3410,\n",
       " 'fabric': 5445,\n",
       " 'hat': 2147,\n",
       " 'university': 1624,\n",
       " 'suicide': 1463,\n",
       " 'believes': 3270,\n",
       " 'fashion': 3074,\n",
       " 'unrelated': 4247,\n",
       " 'exit': 4432,\n",
       " '50+': 7453,\n",
       " 'aim': 2507,\n",
       " 'join': 1180,\n",
       " 'years': 185,\n",
       " 'bench': 3305,\n",
       " 'bar': 960,\n",
       " 'mr.': 4639,\n",
       " 'champions': 1707,\n",
       " 'remains': 3447,\n",
       " 'permit': 6076,\n",
       " 'significant': 1066,\n",
       " 'half': 497,\n",
       " 'cents': 3203,\n",
       " 'loyalty': 4994,\n",
       " 'career': 1702,\n",
       " 'dirt': 3081,\n",
       " 'girls': 957,\n",
       " 'settle': 4884,\n",
       " 'assets': 5183,\n",
       " 'vegetables': 7372,\n",
       " 'wii': 6310,\n",
       " 'units': 1655,\n",
       " 'transfer': 2725,\n",
       " 'desperate': 4056,\n",
       " 'somewhat': 1590,\n",
       " 'integrate': 6833,\n",
       " 'pops': 7135,\n",
       " 'albums': 3867,\n",
       " 'navy': 3926,\n",
       " 'insulted': 7512,\n",
       " 'affairs': 6924,\n",
       " 'choice': 768,\n",
       " 'raped': 4418,\n",
       " 'cease': 7144,\n",
       " 'chips': 6921,\n",
       " '.': 3,\n",
       " 'austin': 3231,\n",
       " 'tpp': 3606,\n",
       " 'grant': 4807,\n",
       " 'mobo': 5614,\n",
       " 'time': 82,\n",
       " 'rifle': 2896,\n",
       " 'primaries': 7193,\n",
       " 'disclaimer': 6219,\n",
       " 'month': 562,\n",
       " 'listening': 1945,\n",
       " 'enterprise': 7897,\n",
       " 'sellers': 7999,\n",
       " 'korean': 7044,\n",
       " 'follow': 710,\n",
       " 'partner': 1240,\n",
       " 'goodness': 5430,\n",
       " 'went': 322,\n",
       " 'pleased': 7298,\n",
       " 'visibility': 6187,\n",
       " 'deal': 460,\n",
       " 'misunderstanding': 5132,\n",
       " 'elected': 4760,\n",
       " 'chains': 4766,\n",
       " 'diving': 5012,\n",
       " 'disaster': 7901,\n",
       " 'applying': 5591,\n",
       " 'procedures': 7804,\n",
       " 'prospects': 6879,\n",
       " 'backgrounds': 7764,\n",
       " 'heal': 2107,\n",
       " 'documented': 6692,\n",
       " 'replacement': 3731,\n",
       " '£60': 6809,\n",
       " 'tu': 4623,\n",
       " 'sensor': 6677,\n",
       " 'behalf': 5752,\n",
       " 'break': 742,\n",
       " 'functioning': 7154,\n",
       " 'convey': 6994,\n",
       " 'cast': 1732,\n",
       " 'rely': 2202,\n",
       " 'requires': 1284,\n",
       " 'nor': 1119,\n",
       " 'and/or': 1427,\n",
       " 'it': 12,\n",
       " 'kiss': 4128,\n",
       " 'language': 1286,\n",
       " 'yellow': 2761,\n",
       " 'rat': 5480,\n",
       " 'bleeding': 5756,\n",
       " 'independent': 3550,\n",
       " 'mount': 3146,\n",
       " 'selected': 3909,\n",
       " 'loss': 1471,\n",
       " 'jumped': 4930,\n",
       " 'mortal': 6987,\n",
       " 'dragging': 5206,\n",
       " 'narrative': 2897,\n",
       " 'respect': 828,\n",
       " 'recipe': 3942,\n",
       " 'indication': 4239,\n",
       " 'nexus': 4751,\n",
       " 'identified': 5610,\n",
       " 'refuses': 6496,\n",
       " 'ourselves': 3244,\n",
       " 'compensation': 4933,\n",
       " 'ideology': 4837,\n",
       " 'on**': 6759,\n",
       " 'must': 386,\n",
       " 'tower': 1897,\n",
       " 'static': 4640,\n",
       " 'allows': 1440,\n",
       " 'feasible': 7978,\n",
       " 'drum': 6904,\n",
       " 'manually': 4327,\n",
       " 'breaches': 7021,\n",
       " 'addicts': 7993,\n",
       " 'privacy': 4836,\n",
       " '1200': 6336,\n",
       " 'processor': 3199,\n",
       " 'distinguish': 4959,\n",
       " 'john': 2025,\n",
       " 're': 3402,\n",
       " 'combined': 3125,\n",
       " 'theater': 5299,\n",
       " 'longer': 586,\n",
       " 'demanding': 4043,\n",
       " 'intro': 3494,\n",
       " 'bud': 4774,\n",
       " 'boxes': 3235,\n",
       " 'monitor': 1943,\n",
       " 'boss': 1299,\n",
       " 'albeit': 4832,\n",
       " 'yeah': 292,\n",
       " 'heavily': 1812,\n",
       " 'fly': 2083,\n",
       " 'motivated': 3593,\n",
       " 'sometimes': 418,\n",
       " 'triple': 4556,\n",
       " 'costco': 7149,\n",
       " 'following': 804,\n",
       " 'roof': 4546,\n",
       " 'occurs': 4202,\n",
       " 'digital': 3218,\n",
       " 'establishment': 5414,\n",
       " 'color': 1117,\n",
       " 'pity': 7872,\n",
       " '**power': 7008,\n",
       " 'mouth': 1957,\n",
       " 'nightmare': 4394,\n",
       " 'central': 2344,\n",
       " 'doing': 210,\n",
       " 'beam': 7210,\n",
       " 'directing': 7294,\n",
       " 'involves': 4924,\n",
       " 'bear': 3105,\n",
       " 'information': 428,\n",
       " 'connect': 2751,\n",
       " 'complaining': 2204,\n",
       " 'premier': 7054,\n",
       " 'mechanics': 1717,\n",
       " 'turns': 1245,\n",
       " 'investigation': 7033,\n",
       " 'theft': 4014,\n",
       " 'suffering': 3407,\n",
       " 'earn': 2088,\n",
       " 'inside': 840,\n",
       " 'footer': 6186,\n",
       " 'entered': 3575,\n",
       " 'them': 71,\n",
       " 'putting': 860,\n",
       " 'boring': 1710,\n",
       " 'idle': 7793,\n",
       " '/r/tipofmytongue': 7119,\n",
       " 'gets': 311,\n",
       " 'much': 105,\n",
       " 'mage': 2829,\n",
       " 'suggestion': 1649,\n",
       " 'financially': 4625,\n",
       " 'factor': 1667,\n",
       " 'makes': 248,\n",
       " 'let': 232,\n",
       " 'lo': 2726,\n",
       " 'villain': 4334,\n",
       " 'hs': 6502,\n",
       " 'edt-0400': 7348,\n",
       " '{': 1236,\n",
       " 'emotion': 3583,\n",
       " 'locals': 7478,\n",
       " '2014': 2993,\n",
       " 'worlds': 2529,\n",
       " 'covering': 5647,\n",
       " 'frankly': 3735,\n",
       " 'say': 134,\n",
       " '2006': 7308,\n",
       " 'paper': 1422,\n",
       " 'interview': 2857,\n",
       " 'launched': 7899,\n",
       " 'bursts': 7102,\n",
       " 'episode': 1190,\n",
       " 'sites': 2253,\n",
       " 'spoken': 5415,\n",
       " 'lovely': 4559,\n",
       " 'upvote': 6495,\n",
       " 'phase': 3059,\n",
       " 'charm': 4987,\n",
       " 'ability': 719,\n",
       " 'cope': 7406,\n",
       " 'sunday': 2894,\n",
       " 'film': 1445,\n",
       " 'trapped': 5097,\n",
       " 'haki': 4193,\n",
       " 'viewers': 4427,\n",
       " 'bothered': 2703,\n",
       " 'studies': 2494,\n",
       " 'others': 337,\n",
       " 'surrounding': 3990,\n",
       " 'så': 3359,\n",
       " 'sf': 5877,\n",
       " 'ron': 6522,\n",
       " 'oompa': 5339,\n",
       " 'direction': 1532,\n",
       " 'court': 1218,\n",
       " 'mom': 1154,\n",
       " 'intent': 4738,\n",
       " 'brackets': 3068,\n",
       " 'void': 3983,\n",
       " 'linux': 2081,\n",
       " 'picks': 2012,\n",
       " 'jeans': 4395,\n",
       " 'blatant': 7602,\n",
       " 'exclusives': 5796,\n",
       " 'committing': 7226,\n",
       " 'enforce': 3077,\n",
       " 'roasted': 6506,\n",
       " 'mins': 5683,\n",
       " 'hint': 4697,\n",
       " 'computers': 2409,\n",
       " '**click': 7192,\n",
       " 'released': 1354,\n",
       " '*are*': 4537,\n",
       " 'renting': 7691,\n",
       " 'balance': 1179,\n",
       " 'led': 1718,\n",
       " 'ready': 1311,\n",
       " 'range': 730,\n",
       " 'meet': 973,\n",
       " 'active': 1126,\n",
       " 'dramatic': 4608,\n",
       " 'etc': 268,\n",
       " 'glass': 1865,\n",
       " 'presumably': 5444,\n",
       " 'item': 831,\n",
       " 'resources': 1461,\n",
       " 'aged': 6909,\n",
       " 'hating': 4431,\n",
       " 'affirmative': 4711,\n",
       " 'consequence': 5548,\n",
       " 'they': 33,\n",
       " 'different': 204,\n",
       " 'guild': 2877,\n",
       " 'diamond': 3852,\n",
       " 'student': 1784,\n",
       " 'liquid': 4200,\n",
       " 'pursue': 6192,\n",
       " 'entirety': 2425,\n",
       " 'hills': 4209,\n",
       " 'content': 526,\n",
       " 'many': 170,\n",
       " 'talked': 1747,\n",
       " 'likes': 1759,\n",
       " 'deficit': 5300,\n",
       " 'shop': 1481,\n",
       " 'cutting': 2770,\n",
       " 'defenses': 7448,\n",
       " 'tips': 1992,\n",
       " 'sue': 6447,\n",
       " 'envy': 2809,\n",
       " 'fc': 6107,\n",
       " 'rain': 3197,\n",
       " 'fork': 6554,\n",
       " 'damned': 3554,\n",
       " 'fool': 4227,\n",
       " 'weights': 7983,\n",
       " '30': 723,\n",
       " 'consciousness': 5362,\n",
       " 'theory': 1134,\n",
       " 'laner': 7303,\n",
       " 'tom': 5744,\n",
       " 'josh': 6582,\n",
       " 'rivalry': 5515,\n",
       " 'hunters': 4231,\n",
       " 'battles': 3492,\n",
       " 'demonstrate': 5915,\n",
       " 'methods': 2720,\n",
       " 'log': 2495,\n",
       " 'minimum': 1459,\n",
       " 'awkward': 2848,\n",
       " 'xd': 4237,\n",
       " 'storyline': 6132,\n",
       " 'accounts': 2132,\n",
       " 'nicotine': 4382,\n",
       " 'it´s': 5551,\n",
       " 'bedroom': 6620,\n",
       " 'xb1': 7819,\n",
       " 'weaknesses': 4539,\n",
       " 'project': 1029,\n",
       " 'reasons': 696,\n",
       " 'miller': 4971,\n",
       " 'pass': 1103,\n",
       " 'url': 4040,\n",
       " 'pricing': 3660,\n",
       " 'teams': 849,\n",
       " 'reliably': 7896,\n",
       " 'smart': 1527,\n",
       " 'producers': 7466,\n",
       " 'discounts*': 7229,\n",
       " '20to': 5304,\n",
       " 'creations': 7143,\n",
       " 'investing': 4455,\n",
       " 'discussion': 701,\n",
       " 'fitting': 5324,\n",
       " 'capitalism': 3098,\n",
       " 'payment': 4064,\n",
       " 'immediate': 3727,\n",
       " 'discipline': 6374,\n",
       " 'san': 3137,\n",
       " 'slurs': 7066,\n",
       " 'immoral': 6312,\n",
       " 'bible': 2102,\n",
       " 'that': 13,\n",
       " 'chickens': 7327,\n",
       " 'ended': 882,\n",
       " 'nowadays': 3905,\n",
       " 'body': 484,\n",
       " 'yes': 272,\n",
       " 'bag': 1956,\n",
       " 'combo': 1653,\n",
       " 'learn': 508,\n",
       " 'bunch': 801,\n",
       " 'support': 324,\n",
       " 'cluster': 7228,\n",
       " 'ap': 3607,\n",
       " 'drm': 5528,\n",
       " 'horror': 3902,\n",
       " 'id': 1901,\n",
       " 'article': 736,\n",
       " 'mexico': 3455,\n",
       " 'clothing': 3542,\n",
       " 'younger': 2260,\n",
       " 'burgle': 7471,\n",
       " 'ie=utf8': 5555,\n",
       " 'any': 81,\n",
       " 'blocks': 2665,\n",
       " 'non-stop': 7874,\n",
       " 'clothes': 2166,\n",
       " 'watching': 677,\n",
       " 'snap': 6473,\n",
       " 'brilliant': 4306,\n",
       " 'total': 829,\n",
       " 'repost': 2982,\n",
       " 'practice': 1148,\n",
       " 'cas': 7921,\n",
       " 'rehabilitation': 6797,\n",
       " 'causing': 2152,\n",
       " 'distinct': 4408,\n",
       " 'describe': 2226,\n",
       " 'analysis': 2955,\n",
       " 'powered': 5587,\n",
       " 'engineering': 3596,\n",
       " 'lt': 1019,\n",
       " 'bet': 1003,\n",
       " 'relation': 6243,\n",
       " '//m.youtube.com/watch': 7503,\n",
       " 'throat': 4783,\n",
       " 'republican': 2609,\n",
       " 'tutorial': 5478,\n",
       " '^^^a': 5099,\n",
       " 'documentary': 7763,\n",
       " 'easily': 571,\n",
       " 'beloved': 7769,\n",
       " 'games': 243,\n",
       " 'ya': 2017,\n",
       " 'worst': 845,\n",
       " 'touch': 1405,\n",
       " 'allah': 6089,\n",
       " 'upcoming': 3688,\n",
       " 'titans': 6678,\n",
       " '1000': 1853,\n",
       " 'persons': 5571,\n",
       " 'saying': 245,\n",
       " 'ein': 5842,\n",
       " 'profiles': 5546,\n",
       " 'hose': 5954,\n",
       " 'clarify': 5619,\n",
       " 'gear': 1185,\n",
       " 'realm': 4500,\n",
       " 'dressing': 7751,\n",
       " 'resist': 6371,\n",
       " 'boobs': 4629,\n",
       " 'diet': 1818,\n",
       " 'facebook': 2121,\n",
       " 'discounts': 7505,\n",
       " 'political': 893,\n",
       " 'seats': 3992,\n",
       " 'lawful': 6459,\n",
       " 'interior': 5908,\n",
       " 'pissed': 2424,\n",
       " 'target': 1016,\n",
       " 'reads': 6221,\n",
       " 'oppressive': 7939,\n",
       " 'fancy': 4566,\n",
       " '*words*': 6773,\n",
       " 'convinced': 2142,\n",
       " 'stats': 1128,\n",
       " 'rich': 1770,\n",
       " 'grow': 1160,\n",
       " 'encounters': 5161,\n",
       " 'idiot': 1842,\n",
       " 'additionally': 3444,\n",
       " '7.': 4934,\n",
       " 'violent': 2440,\n",
       " 'world': 257,\n",
       " 'determined': 3000,\n",
       " 'barely': 1505,\n",
       " 'peace': 2117,\n",
       " 'temp': 7026,\n",
       " 'return': 983,\n",
       " 'bodies': 2783,\n",
       " 'ruins': 7887,\n",
       " 'about': 54,\n",
       " 'editing': 3835,\n",
       " 'karma': 1272,\n",
       " 'simon': 7472,\n",
       " 'higher': 518,\n",
       " 'prey': 6783,\n",
       " 'pieces': 1584,\n",
       " 'irc': 7607,\n",
       " 'sides': 1585,\n",
       " 'emotionally': 3824,\n",
       " 'cat': 1431,\n",
       " 'convenient': 4590,\n",
       " 'american': 805,\n",
       " 'previously': 2787,\n",
       " 'deals': 2157,\n",
       " 'morality': 5367,\n",
       " 'ebay': 2865,\n",
       " 'dice': 2618,\n",
       " 'abstract': 4451,\n",
       " 'clg': 5676,\n",
       " 'strict': 4041,\n",
       " 'engage': 2891,\n",
       " 'teenager': 6871,\n",
       " 'sequence': 4714,\n",
       " 'reminders': 6505,\n",
       " 'ancients': 6479,\n",
       " 'panel': 3936,\n",
       " 'pretend': 2555,\n",
       " 'originally': 2587,\n",
       " 'unsure': 4589,\n",
       " 'strengths': 7320,\n",
       " 'forms': 3422,\n",
       " 'largely': 2388,\n",
       " 'programming': 5646,\n",
       " 'documentation': 7359,\n",
       " 'animation': 4046,\n",
       " 'applicable': 5014,\n",
       " 'tells': 1399,\n",
       " 'ghost': 4896,\n",
       " 'legs': 2477,\n",
       " 'enough': 209,\n",
       " 'des': 4051,\n",
       " 'mob': 5170,\n",
       " 'cheese': 2650,\n",
       " 'suicides': 4538,\n",
       " 'insist': 6775,\n",
       " 'songs': 1417,\n",
       " 'greedy': 4744,\n",
       " 'sample': 2742,\n",
       " 'starts': 1225,\n",
       " 'nursing': 6451,\n",
       " 'mirrors': 6922,\n",
       " 'gf': 3654,\n",
       " 'ref': 5293,\n",
       " 'warrior': 2412,\n",
       " 'long-term': 6988,\n",
       " 'drawn': 3756,\n",
       " 'serving': 5636,\n",
       " 'hesitate': 6075,\n",
       " 'lifestyle': 2481,\n",
       " 'realised': 6765,\n",
       " 'bump': 7371,\n",
       " 'don’t': 2379,\n",
       " 'flip': 3163,\n",
       " 'brother': 987,\n",
       " 'underlying': 6724,\n",
       " 'aspects': 3314,\n",
       " 'sells': 6612,\n",
       " 'effectively': 2864,\n",
       " 'hop': 5298,\n",
       " 'violation': 3323,\n",
       " '*follows*': 6818,\n",
       " 'generation': 3030,\n",
       " 'wiki_-rule_2-': 5405,\n",
       " 'bets': 6721,\n",
       " 'challenge': 1772,\n",
       " 'bike': 1528,\n",
       " 'plug': 4077,\n",
       " 'ps': 4168,\n",
       " 'trait': 7757,\n",
       " 'restricted': 5612,\n",
       " 'golf': 7683,\n",
       " \"n't\": 17,\n",
       " 'secondary': 3038,\n",
       " 'obligation': 6455,\n",
       " 'relaxing': 7356,\n",
       " 'campus': 3908,\n",
       " 'super': 468,\n",
       " 'official': 1488,\n",
       " 'current': 502,\n",
       " 'expensive': 996,\n",
       " 'abusive': 4758,\n",
       " 'implying': 3385,\n",
       " 'disorder': 6200,\n",
       " 'bros': 6580,\n",
       " 'notes': 2354,\n",
       " 'august': 2430,\n",
       " 'feat': 4147,\n",
       " 'musician': 5399,\n",
       " 'awareness': 3889,\n",
       " 'travelling': 7739,\n",
       " 'belief': 4442,\n",
       " 'magazines': 7551,\n",
       " 'idiotic': 7286,\n",
       " 'signal': 3621,\n",
       " 'equality': 3662,\n",
       " 'witcher': 6870,\n",
       " 'back': 142,\n",
       " 'kratom': 7488,\n",
       " 'unfortunately': 865,\n",
       " 'arsenal': 3667,\n",
       " 'windows': 933,\n",
       " 'anime': 2646,\n",
       " 'days': 323,\n",
       " 'pcpartpicker': 4267,\n",
       " 'clinton': 2227,\n",
       " 'bans': 3440,\n",
       " 'pitch': 3445,\n",
       " 'video': 332,\n",
       " 'sign': 1177,\n",
       " 'lies': 3120,\n",
       " 'various': 1296,\n",
       " 'harmless': 6642,\n",
       " 'edge': 2116,\n",
       " 'moved': 1289,\n",
       " 'addict': 4626,\n",
       " 'shitty': 1221,\n",
       " 'lfr': 5098,\n",
       " 'whip': 5835,\n",
       " 'eligible': 5658,\n",
       " 'under': 409,\n",
       " 'george': 4433,\n",
       " 'announced': 4114,\n",
       " 'pve': 3831,\n",
       " 'bow': 4199,\n",
       " 'wishes': 5031,\n",
       " 'leads': 2268,\n",
       " 'real': 297,\n",
       " 'brick': 6133,\n",
       " 'reform': 5315,\n",
       " 'plates': 6396,\n",
       " 'asian': 2713,\n",
       " 'ease': 4891,\n",
       " '20a': 7844,\n",
       " 'restrooms': 7749,\n",
       " 'lungs': 4811,\n",
       " 'mmos': 7695,\n",
       " 'purchased': 3500,\n",
       " 'struck': 6540,\n",
       " 'salts': 6610,\n",
       " 'holes': 4130,\n",
       " 'pin': 3755,\n",
       " 'find': 195,\n",
       " 'enter': 1607,\n",
       " 'vacation': 4950,\n",
       " 'play': 193,\n",
       " 'hog': 7818,\n",
       " 'breaker': 6417,\n",
       " 'deposit': 6412,\n",
       " 'deny': 3328,\n",
       " 'pulls': 5839,\n",
       " 'ice': 1570,\n",
       " 'shoes': 1882,\n",
       " 'vision': 2626,\n",
       " 'day': 203,\n",
       " 'search': 920,\n",
       " 'royal': 7479,\n",
       " 'procedure': 3479,\n",
       " 'equate': 6490,\n",
       " 'rejection': 5550,\n",
       " 'exist': 912,\n",
       " 'awesome': 584,\n",
       " 'nbsp': 1773,\n",
       " 'unwilling': 7880,\n",
       " 'requests': 2827,\n",
       " 'prevents': 4845,\n",
       " 'formaldehyde': 5125,\n",
       " 'juggernaut': 6307,\n",
       " 'snapshots': 5859,\n",
       " 'regen': 3478,\n",
       " 'looked': 663,\n",
       " 'chunk': 5494,\n",
       " '003f': 6401,\n",
       " 'liability': 5927,\n",
       " 'carb': 7349,\n",
       " 'obama': 2594,\n",
       " 'bismark': 3809,\n",
       " 'dispute': 5421,\n",
       " 'magnetic': 6968,\n",
       " 'college': 870,\n",
       " 'go': 120,\n",
       " '8th': 5543,\n",
       " 'overlooked': 6684,\n",
       " 'moses': 6116,\n",
       " 'allies': 3792,\n",
       " 'the': 4,\n",
       " 'lung': 7437,\n",
       " 'per': 472,\n",
       " 'unfortunate': 5053,\n",
       " 'approaches': 5738,\n",
       " 'youth': 4990,\n",
       " 'resident': 7230,\n",
       " 'bs': 3389,\n",
       " 'budget': 1342,\n",
       " 'aired': 6826,\n",
       " '0aplease': 3127,\n",
       " 'handing': 5625,\n",
       " 'influence': 1771,\n",
       " 'family': 419,\n",
       " 'expanded': 6881,\n",
       " 'battery': 1049,\n",
       " 'dungeon': 3435,\n",
       " 'shoulders': 5347,\n",
       " 'crossed': 5238,\n",
       " 'murders': 4958,\n",
       " 'intelligent': 3350,\n",
       " '/r/advice': 6305,\n",
       " 'dump': 3640,\n",
       " 'simulator': 7969,\n",
       " 'technique': 4105,\n",
       " '140': 6875,\n",
       " 'impressed': 4820,\n",
       " 'wheels': 4224,\n",
       " 'show': 307,\n",
       " '~': 3352,\n",
       " '*at': 7935,\n",
       " 'cancelled': 7000,\n",
       " 'mystery': 4551,\n",
       " 'dishes': 6707,\n",
       " 'skin': 1382,\n",
       " 'bucket': 5967,\n",
       " 'interviews': 3980,\n",
       " 'cheap': 792,\n",
       " 'wise': 1861,\n",
       " 'plan': 605,\n",
       " 'approach': 1514,\n",
       " '^|': 2064,\n",
       " 'wish': 613,\n",
       " 'incorrect': 2789,\n",
       " 'sorts': 2504,\n",
       " 'purposes': 2823,\n",
       " 'americans': 1785,\n",
       " 'dungeons': 3373,\n",
       " '180': 5575,\n",
       " 'invention': 6024,\n",
       " 'killed': 953,\n",
       " 'rhythm': 7923,\n",
       " 'consumption': 6454,\n",
       " 'have': 21,\n",
       " ...}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_to_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2761"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_to_index['yellow']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i, sent in enumerate(tokenized_sentences):\n",
    "    tokenized_sentences[i] = [w if w in word_to_index else unknown_token for w in sent]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "X_train = np.asarray([[word_to_index[w] for w in sent[:-1]] for sent in tokenized_sentences])\n",
    "y_train = np.asarray([[word_to_index[w] for w in sent[1:]] for sent in tokenized_sentences])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x:\n",
      "SENTENCE_START no one is going to be honest enough to run the check , see they 're a felon , and then all of a sudden immediately turn dishonest and say `` nah , you know what , here 's your gun anyway . ''\n",
      "[1, 73, 64, 14, 125, 6, 27, 1131, 209, 6, 327, 4, 330, 5, 113, 33, 76, 8, 4912, 5, 9, 85, 53, 10, 8, 3196, 1015, 493, 7835, 9, 134, 50, 3132, 5, 11, 96, 52, 5, 129, 18, 38, 315, 578, 3, 41]\n",
      "\n",
      "y:\n",
      "no one is going to be honest enough to run the check , see they 're a felon , and then all of a sudden immediately turn dishonest and say `` nah , you know what , here 's your gun anyway . '' SENTENCE_END\n",
      "[73, 64, 14, 125, 6, 27, 1131, 209, 6, 327, 4, 330, 5, 113, 33, 76, 8, 4912, 5, 9, 85, 53, 10, 8, 3196, 1015, 493, 7835, 9, 134, 50, 3132, 5, 11, 96, 52, 5, 129, 18, 38, 315, 578, 3, 41, 2]\n"
     ]
    }
   ],
   "source": [
    "x_example, y_example = X_train[10], y_train[10]\n",
    "print(\"x:\\n%s\\n%s\" % (\" \".join([wordlist[x] for x in x_example]), x_example))\n",
    "print(\"\\ny:\\n%s\\n%s\" % (\" \".join([wordlist[x] for x in y_example]), y_example))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "79170"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ [1, 7, 3574, 8, 156, 795, 26, 224, 9, 33, 21, 204, 5127, 350, 92, 7, 67, 208, 6, 3],\n",
       "       [1, 12, 18, 8, 3092, 6180, 0, 0, 6180, 3],\n",
       "       [1, 984, 1476, 228, 598, 16, 774, 3487, 2956, 5, 0, 598, 472, 6061, 5, 491, 598, 472, 6140, 2739, 5, 9, 72, 5702, 16, 0, 0, 3],\n",
       "       ...,\n",
       "       [1, 0, 5, 42, 0, 5, 14, 64, 10, 153, 756, 0, 58, 4, 0, 13, 99, 17, 619, 68, 12, 110, 21, 3],\n",
       "       [1, 39, 145, 3518, 25, 0, 0, 0, 9, 1045, 563, 0, 0, 0, 0, 3],\n",
       "       [1, 4, 4297, 20, 0, 19, 175, 13, 233, 75, 102, 1290, 15, 25, 162, 9, 13, 7, 161, 17, 132, 4, 563, 69, 12, 18, 785, 6, 27, 0, 3]], dtype=object)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['SENTENCE_START',\n",
       " 'no',\n",
       " 'one',\n",
       " 'is',\n",
       " 'going',\n",
       " 'to',\n",
       " 'be',\n",
       " 'honest',\n",
       " 'enough',\n",
       " 'to',\n",
       " 'run',\n",
       " 'the',\n",
       " 'check',\n",
       " ',',\n",
       " 'see',\n",
       " 'they',\n",
       " \"'re\",\n",
       " 'a',\n",
       " 'felon',\n",
       " ',',\n",
       " 'and',\n",
       " 'then',\n",
       " 'all',\n",
       " 'of',\n",
       " 'a',\n",
       " 'sudden',\n",
       " 'immediately',\n",
       " 'turn',\n",
       " 'dishonest',\n",
       " 'and',\n",
       " 'say',\n",
       " '``',\n",
       " 'nah',\n",
       " ',',\n",
       " 'you',\n",
       " 'know',\n",
       " 'what',\n",
       " ',',\n",
       " 'here',\n",
       " \"'s\",\n",
       " 'your',\n",
       " 'gun',\n",
       " 'anyway',\n",
       " '.',\n",
       " \"''\",\n",
       " 'SENTENCE_END']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_sentences[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "x = X_train\n",
    "max_length = max(len(row) for row in x)\n",
    "x_padded = np.array([row + [0] * (max_length - len(row)) for row in x])\n",
    "x_tensor = tf.convert_to_tensor(x_padded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "x = y_train\n",
    "max_length = max(len(row) for row in x)\n",
    "y_padded = np.array([row + [0] * (max_length - len(row)) for row in x])\n",
    "y_tensor = tf.convert_to_tensor(y_padded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   1,    7, 3574, ...,    0,    0,    0],\n",
       "       [   1,   12,   18, ...,    0,    0,    0],\n",
       "       [   1,  984, 1476, ...,    0,    0,    0],\n",
       "       ..., \n",
       "       [   1,    0,    5, ...,    0,    0,    0],\n",
       "       [   1,   39,  145, ...,    0,    0,    0],\n",
       "       [   1,    4, 4297, ...,    0,    0,    0]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_padded "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   7, 3574,    8, ...,    0,    0,    0],\n",
       "       [  12,   18,    8, ...,    0,    0,    0],\n",
       "       [ 984, 1476,  228, ...,    0,    0,    0],\n",
       "       ..., \n",
       "       [   0,    5,   42, ...,    0,    0,    0],\n",
       "       [  39,  145, 3518, ...,    0,    0,    0],\n",
       "       [   4, 4297,   20, ...,    0,    0,    0]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_padded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'embedding_lookup:0' shape=(2, 200) dtype=float32>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "z = [2763,0]\n",
    "tf.nn.embedding_lookup(embeddings, z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.12261748,  1.07197416, -0.18724339, -0.09346128, -1.0280689 ,\n",
       "         0.1638882 , -0.10434432, -0.73139   ,  1.1562748 , -0.30800653,\n",
       "        -0.69865322, -0.07324108,  0.30612069, -0.25338396, -0.56239402,\n",
       "        -0.8646791 , -0.44424289,  0.05422308,  0.17322272,  0.94733042,\n",
       "        -0.10079843, -0.31137192, -0.5167346 , -0.31001687, -1.7446804 ,\n",
       "         0.93849123,  0.46673664,  0.21381432,  0.07874353,  0.39004678,\n",
       "         0.97723538, -0.32416728, -0.1724211 ,  1.12379622,  0.75076693,\n",
       "         0.33819035,  0.00903004,  0.79284203, -1.18947971,  0.12093852,\n",
       "         0.508798  , -1.32484865,  0.38485217,  0.92830265,  0.07834905,\n",
       "        -0.98400843,  0.05005199,  0.06951942, -0.41476256, -1.52646422,\n",
       "        -0.50009418, -0.04572278, -1.37805736, -0.74078822,  0.45445547,\n",
       "         0.24622086, -1.79271388, -0.74465311, -0.24273418, -0.07206631,\n",
       "        -0.57831132,  0.66648704, -0.26680511, -0.24319315,  0.9310962 ,\n",
       "         0.50152546,  0.42568713, -0.77300262,  0.49587435,  0.04260627,\n",
       "        -1.04713082,  0.35527635, -0.0688889 , -0.63499361,  0.89501768,\n",
       "        -0.97767889,  0.30219111, -0.1088403 , -0.15363741, -0.08672671,\n",
       "         1.09477484, -0.93477154, -0.60068333, -0.10621764, -0.07574978,\n",
       "        -0.25365806, -0.34191072,  0.28697371, -0.28658068, -0.89975321,\n",
       "         0.65522319, -0.93202674,  0.62364495,  0.67186302, -0.40116894,\n",
       "        -0.20932135, -0.0312804 ,  0.35917532,  0.13670054,  0.99974751,\n",
       "         0.44703659, -0.2825852 , -1.12173033, -0.59565282, -0.15846848,\n",
       "        -0.05050446,  0.59091568, -0.3652325 ,  0.15137213,  0.56563634,\n",
       "        -0.08465663, -0.17834792, -0.19769245, -0.07125506,  0.12932736,\n",
       "        -0.98932731, -0.43753111, -0.83292854, -0.55765688, -0.16103581,\n",
       "         0.78216779,  0.41132632, -0.37893268, -0.84018862,  0.33617529,\n",
       "         0.24418172,  0.92062443, -0.83526915, -1.28486514, -0.29423216,\n",
       "        -0.45324385,  0.81973088, -0.22406843, -1.29551935, -0.17559031,\n",
       "        -0.74134946,  0.74614245, -0.10213803, -0.70874542, -0.3388851 ,\n",
       "         0.60806608,  0.75660765,  1.01503682,  0.08084998, -0.2965056 ,\n",
       "        -0.67858881, -0.75753534,  0.0928278 ,  0.1991176 , -0.43728259,\n",
       "         0.22031599, -0.89828283,  0.4138816 , -1.05797899, -1.06877995,\n",
       "        -0.9122082 , -0.11976545, -0.04836359, -0.19944756, -0.72426993,\n",
       "         0.01710257, -0.74765605,  0.98050338,  0.38384309,  0.53539932,\n",
       "         0.3315219 , -0.97968781,  0.74436831, -0.89029837,  0.09220302,\n",
       "         0.33793166,  0.85141546,  0.06077665,  0.40476263, -1.78229702,\n",
       "        -0.01793975, -0.63209969,  0.35889807, -0.07965025,  0.46471658,\n",
       "        -0.46244788,  0.50937223,  0.12470099,  0.95265573, -0.31790382,\n",
       "        -0.56868064, -0.1102003 , -0.44430715,  0.09768397,  0.67542017,\n",
       "         0.798581  ,  1.45366848, -0.30410787,  1.02984726, -0.60850763,\n",
       "        -0.80168384, -0.94777727,  0.02224622, -0.32179251, -0.63903677],\n",
       "       [ 0.24544086, -0.75733   , -0.18160024,  0.34181854, -0.32349497,\n",
       "         0.60794938, -0.09855039, -0.44265288,  1.09958506,  0.14901857,\n",
       "        -0.27898619,  0.1304639 , -0.0696241 ,  0.28675073,  0.59513891,\n",
       "         0.71870011,  0.43750817,  0.02555501,  0.81161273,  0.38767189,\n",
       "         0.43651217, -0.05338576, -0.09977165,  0.25038832,  0.89707267,\n",
       "        -0.79343128,  0.01538635, -0.12528628,  0.21615484,  0.14545128,\n",
       "         0.32773316,  0.4306964 ,  0.25240287,  0.2783078 ,  0.52379   ,\n",
       "        -0.58565819,  0.60707092,  0.52376717, -0.06989059, -0.61551011,\n",
       "        -1.02004695,  0.88688421, -0.38562083, -0.26949012,  0.51358259,\n",
       "        -0.53529632, -0.08803543,  0.80867368,  0.06622888, -0.34425631,\n",
       "        -0.14629787,  0.22719893, -0.15698816, -0.06723876, -0.17649142,\n",
       "        -0.13103357, -0.15368485, -0.12036225,  0.25663322,  0.29555303,\n",
       "        -0.62799406, -0.73106098, -0.21531858, -0.44110042,  0.16633531,\n",
       "        -0.07128602, -0.61695433, -0.71234566, -0.03555042, -0.05016956,\n",
       "        -0.2991311 ,  0.53893507,  0.1489706 ,  0.28213894,  0.52491689,\n",
       "         0.26506299, -0.593606  , -0.45267576,  0.49179864, -0.4996103 ,\n",
       "         0.20168479, -0.90398723, -0.12367356, -0.2154301 , -0.20956442,\n",
       "         0.4534643 ,  0.34042281,  0.28000316, -0.54533124, -0.02944471,\n",
       "         0.13611898, -0.19757539, -0.64464194, -0.20395102,  0.81429684,\n",
       "        -0.2077352 ,  0.58445066, -0.50202543, -0.03950464,  0.3035135 ,\n",
       "        -0.42523295, -0.20850249,  0.09433153, -0.14647293,  0.98714381,\n",
       "         0.90842819,  0.05919406,  0.06707576,  0.08717984,  0.42470807,\n",
       "        -0.70760417, -0.10468473,  0.79125708,  0.64367938, -0.91663265,\n",
       "        -0.05102736, -1.01312351, -0.27674112,  0.40672404, -0.46182072,\n",
       "        -0.03302349, -0.08395046, -0.73022735,  0.00236686, -0.24466936,\n",
       "        -0.21927129, -0.1514646 ,  0.18536693, -0.36546186, -0.10102502,\n",
       "         0.65456927, -0.5380764 , -0.6385268 ,  0.61949998, -0.79934734,\n",
       "        -0.06752543, -0.2926935 , -0.05751787, -0.3003242 , -0.13371426,\n",
       "         0.1366283 , -0.14850983,  0.00919609, -0.99188578,  0.36997005,\n",
       "        -0.04402028,  0.39337769,  0.54104847, -0.20387384,  0.519943  ,\n",
       "        -0.00740454,  0.59273821,  0.03956579,  0.39824224,  0.10045473,\n",
       "         0.11037935, -0.40599144,  0.71609753,  0.56870693,  0.11006503,\n",
       "         0.51094437, -0.43039146, -0.12652114,  0.30210775,  0.23981988,\n",
       "        -0.55958986,  0.14639595,  0.40041786, -0.57849342,  0.10284977,\n",
       "        -0.63273913,  0.30243427,  0.15815997, -0.53089285, -0.15150152,\n",
       "         0.18484156, -0.04776923, -0.28951216,  0.01005263,  0.17165861,\n",
       "         0.63619888,  0.74669635,  0.62313831, -0.50607014,  0.09203534,\n",
       "        -0.08955956,  0.28671408,  0.41421407, -0.07690708,  0.39407343,\n",
       "        -0.17668158,  0.6105215 ,  0.08413029, -0.16711551, -0.09807585,\n",
       "         0.30416161,  1.08374476,  0.12860048,  0.04273024,  0.514979  ]], dtype=float32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.InteractiveSession().run(tf.nn.embedding_lookup(embeddings, z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tf.InteractiveSession().run(tf.nn.embedding_lookup(embeddings, x_padded[:3]))[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(79170, 79170)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_padded),len(y_padded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xtrain,ytrain = x_padded[:1000], y_padded[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 1000)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(xtrain),len(ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xtest,ytest = x_padded[1200:1400], y_padded[1200:1400]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200, 200)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(xtest),len(ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "from tensorflow.contrib import rnn \n",
    "hm_epochs = 150\n",
    "batch_size = 20\n",
    "num_steps = 791\n",
    "state_size = 200\n",
    "vocab_size = 8000\n",
    "\n",
    "# Placeholders\n",
    "x = tf.placeholder(tf.int32, [batch_size, None]) # [batch_size, num_steps]\n",
    "seqlen = tf.placeholder(tf.int32, [batch_size])\n",
    "y = tf.placeholder(tf.int32, [batch_size,None])\n",
    "keep_prob = tf.constant(1.0)\n",
    "sequencelength = [len(X_train[i]) for i in X_train][:1000]\n",
    "testsequencelength = [len(y_train[i]) for i in y_train][1200:1400]\n",
    "def train_neural_network(x): \n",
    "    \n",
    "        def next_batch(step):\n",
    "            p,q = xtrain[batch_size*step:batch_size*(step+1)], ytrain[batch_size*step:batch_size*(step+1)]\n",
    "            r = sequencelength[batch_size*step:batch_size*(step+1)]\n",
    "            return p,q,r\n",
    "        \n",
    "        def test_batch(stp):    \n",
    "            a,b = xtest[batch_size*stp:batch_size*(stp+1)], ytest[batch_size*stp:batch_size*(stp+1)]\n",
    "            c = testsequencelength[batch_size*stp:batch_size*(stp+1)]\n",
    "            return a,b,c\n",
    "              \n",
    "        def lstm_neural_network(x):\n",
    "            # Embedding layer\n",
    "            rnn_inputs = tf.nn.embedding_lookup(embeddings, x)\n",
    "            print(rnn_inputs)\n",
    "            # RNN\n",
    "            initial_state = tf.tile(tf.get_variable('initial_state', [1, state_size],\n",
    "                                    initializer=tf.constant_initializer(0.0)),[batch_size,1])\n",
    "            #inputs = tf.unstack(rnn_inputs, num=num_steps, axis=1)   \n",
    "            cell = tf.contrib.rnn.GRUCell(state_size)\n",
    "            cell = tf.contrib.rnn.DropoutWrapper(cell=cell, output_keep_prob = 0.5)\n",
    "            print(\"this is rnn going in:\", rnn_inputs)\n",
    "            print(\"this is the seqlen:\", seqlen)\n",
    "            rnn_outputs, final_state = tf.nn.dynamic_rnn(cell, rnn_inputs, sequence_length=seqlen,\n",
    "                                                                   initial_state=initial_state)\n",
    "\n",
    "            rnn_output = tf.reshape(tf.concat(axis=1, values=rnn_outputs), [-1, state_size])\n",
    "            print(\"this is the output:\",rnn_output)\n",
    "            softmax_w = tf.get_variable(\"softmax_w\", [state_size, vocab_size], dtype=tf.float32)\n",
    "            softmax_b = tf.get_variable(\"softmax_b\", [vocab_size], dtype=tf.float32)\n",
    "            logits = tf.matmul(rnn_output, softmax_w) + softmax_b\n",
    "            return logits\n",
    "\n",
    "        prediction = lstm_neural_network(x)\n",
    "        loss = tf.contrib.legacy_seq2seq.sequence_loss_by_example(\n",
    "            [prediction],\n",
    "            [tf.reshape(y[:batch_size], [-1])],\n",
    "            [tf.ones([batch_size * num_steps], dtype=tf.float32)])\n",
    "        cost = tf.reduce_sum(loss) / batch_size\n",
    "        optimizer = tf.train.AdamOptimizer().minimize(cost)   \n",
    "        saver = tf.train.Saver()\n",
    "        \n",
    "        with tf.Session() as sess:\n",
    "            sess.run(tf.initialize_all_variables())\n",
    "            for epoch in range(hm_epochs):\n",
    "                epoch_loss = 0 \n",
    "                for step in range(int(len(xtrain)/batch_size)):\n",
    "                    epoch_x, epoch_y, sl = next_batch(step)\n",
    "                    _, c = sess.run([optimizer, cost], feed_dict={x: epoch_x, y: epoch_y, seqlen: sl})\n",
    "                    epoch_loss += c\n",
    "                print('Epoch', epoch, 'completed out of',hm_epochs,'loss:',epoch_loss)\n",
    "            save_path = saver.save(sess, \"./model/\")\n",
    "            print(\"Model saved in file: %s\" % save_path)\n",
    "            \n",
    "            for stp in range(int(len(xtest)/batch_size)):\n",
    "                s,u,v = test_batch(stp)\n",
    "                correct = tf.equal((tf.argmax(prediction,1)),tf.cast(tf.reshape(tf.concat(axis=1, values= u), [-1]),tf.int64))\n",
    "                accuracy = tf.reduce_mean(tf.cast(correct, 'float'))\n",
    "                print( 'Batch #', stp, 'Accuracy by each batch:',accuracy.eval({x: s, y: u,seqlen: v}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"embedding_lookup:0\", shape=(20, ?, 200), dtype=float32)\n",
      "this is rnn going in: Tensor(\"embedding_lookup:0\", shape=(20, ?, 200), dtype=float32)\n",
      "this is the seqlen: Tensor(\"Placeholder_1:0\", shape=(20,), dtype=int32)\n",
      "this is the output: Tensor(\"Reshape:0\", shape=(?, 200), dtype=float32)\n",
      "WARNING:tensorflow:From <ipython-input-28-86b57aa88aae>:60: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Use `tf.global_variables_initializer` instead.\n",
      "Epoch 0 completed out of 150 loss: 350678.928223\n",
      "Epoch 1 completed out of 150 loss: 345966.856934\n",
      "Epoch 2 completed out of 150 loss: 342066.316895\n",
      "Epoch 3 completed out of 150 loss: 338180.718262\n",
      "Epoch 4 completed out of 150 loss: 334287.438965\n",
      "Epoch 5 completed out of 150 loss: 330367.032715\n",
      "Epoch 6 completed out of 150 loss: 326431.490234\n",
      "Epoch 7 completed out of 150 loss: 322506.257813\n",
      "Epoch 8 completed out of 150 loss: 318592.100586\n",
      "Epoch 9 completed out of 150 loss: 314680.591309\n",
      "Epoch 10 completed out of 150 loss: 310766.852051\n",
      "Epoch 11 completed out of 150 loss: 306851.881836\n",
      "Epoch 12 completed out of 150 loss: 302934.783691\n",
      "Epoch 13 completed out of 150 loss: 299012.45166\n",
      "Epoch 14 completed out of 150 loss: 295101.923828\n",
      "Epoch 15 completed out of 150 loss: 291176.31543\n",
      "Epoch 16 completed out of 150 loss: 287256.210449\n",
      "Epoch 17 completed out of 150 loss: 283332.915527\n",
      "Epoch 18 completed out of 150 loss: 279407.555176\n",
      "Epoch 19 completed out of 150 loss: 275485.479004\n",
      "Epoch 20 completed out of 150 loss: 271558.453613\n",
      "Epoch 21 completed out of 150 loss: 267632.561035\n",
      "Epoch 22 completed out of 150 loss: 263719.630371\n",
      "Epoch 23 completed out of 150 loss: 259807.145508\n",
      "Epoch 24 completed out of 150 loss: 255881.26709\n",
      "Epoch 25 completed out of 150 loss: 251953.21875\n",
      "Epoch 26 completed out of 150 loss: 248035.20459\n",
      "Epoch 27 completed out of 150 loss: 244118.429688\n",
      "Epoch 28 completed out of 150 loss: 240207.442871\n",
      "Epoch 29 completed out of 150 loss: 236294.900391\n",
      "Epoch 30 completed out of 150 loss: 232400.598145\n",
      "Epoch 31 completed out of 150 loss: 228490.13916\n",
      "Epoch 32 completed out of 150 loss: 224577.864746\n",
      "Epoch 33 completed out of 150 loss: 220659.337891\n",
      "Epoch 34 completed out of 150 loss: 216750.615723\n",
      "Epoch 35 completed out of 150 loss: 212860.236816\n",
      "Epoch 36 completed out of 150 loss: 208988.938965\n",
      "Epoch 37 completed out of 150 loss: 205120.359863\n",
      "Epoch 38 completed out of 150 loss: 201263.947754\n",
      "Epoch 39 completed out of 150 loss: 197389.843994\n",
      "Epoch 40 completed out of 150 loss: 193508.760254\n",
      "Epoch 41 completed out of 150 loss: 189646.959473\n",
      "Epoch 42 completed out of 150 loss: 185784.479492\n",
      "Epoch 43 completed out of 150 loss: 181940.862793\n",
      "Epoch 44 completed out of 150 loss: 178102.577148\n",
      "Epoch 45 completed out of 150 loss: 174279.637207\n",
      "Epoch 46 completed out of 150 loss: 170467.232666\n",
      "Epoch 47 completed out of 150 loss: 166669.972656\n",
      "Epoch 48 completed out of 150 loss: 162860.309326\n",
      "Epoch 49 completed out of 150 loss: 159088.438477\n",
      "Epoch 50 completed out of 150 loss: 155314.529541\n",
      "Epoch 51 completed out of 150 loss: 151559.339111\n",
      "Epoch 52 completed out of 150 loss: 147814.80835\n",
      "Epoch 53 completed out of 150 loss: 144059.306152\n",
      "Epoch 54 completed out of 150 loss: 140329.423096\n",
      "Epoch 55 completed out of 150 loss: 136614.444336\n",
      "Epoch 56 completed out of 150 loss: 132936.823242\n",
      "Epoch 57 completed out of 150 loss: 129275.835693\n",
      "Epoch 58 completed out of 150 loss: 125640.106445\n",
      "Epoch 59 completed out of 150 loss: 122026.173096\n",
      "Epoch 60 completed out of 150 loss: 118443.778809\n",
      "Epoch 61 completed out of 150 loss: 114890.879639\n",
      "Epoch 62 completed out of 150 loss: 111360.656006\n",
      "Epoch 63 completed out of 150 loss: 107868.854004\n",
      "Epoch 64 completed out of 150 loss: 104409.975342\n",
      "Epoch 65 completed out of 150 loss: 100985.851196\n",
      "Epoch 66 completed out of 150 loss: 97611.7305908\n",
      "Epoch 67 completed out of 150 loss: 94273.0817871\n",
      "Epoch 68 completed out of 150 loss: 90980.9283447\n",
      "Epoch 69 completed out of 150 loss: 87744.0731201\n",
      "Epoch 70 completed out of 150 loss: 84556.7877197\n",
      "Epoch 71 completed out of 150 loss: 81431.3408203\n",
      "Epoch 72 completed out of 150 loss: 78360.80896\n",
      "Epoch 73 completed out of 150 loss: 75329.6392822\n",
      "Epoch 74 completed out of 150 loss: 72402.5489502\n",
      "Epoch 75 completed out of 150 loss: 69522.583374\n",
      "Epoch 76 completed out of 150 loss: 66723.0979004\n",
      "Epoch 77 completed out of 150 loss: 63969.5648193\n",
      "Epoch 78 completed out of 150 loss: 61315.2614746\n",
      "Epoch 79 completed out of 150 loss: 58745.7344971\n",
      "Epoch 80 completed out of 150 loss: 56234.4147949\n",
      "Epoch 81 completed out of 150 loss: 53798.3474121\n",
      "Epoch 82 completed out of 150 loss: 51464.8510742\n",
      "Epoch 83 completed out of 150 loss: 49199.3415527\n",
      "Epoch 84 completed out of 150 loss: 47024.9447632\n",
      "Epoch 85 completed out of 150 loss: 44928.7296143\n",
      "Epoch 86 completed out of 150 loss: 42921.9789429\n",
      "Epoch 87 completed out of 150 loss: 41011.8931274\n",
      "Epoch 88 completed out of 150 loss: 39149.9326172\n",
      "Epoch 89 completed out of 150 loss: 37381.4169922\n",
      "Epoch 90 completed out of 150 loss: 35690.0912476\n",
      "Epoch 91 completed out of 150 loss: 34079.1611328\n",
      "Epoch 92 completed out of 150 loss: 32565.6756592\n",
      "Epoch 93 completed out of 150 loss: 31086.6851807\n",
      "Epoch 94 completed out of 150 loss: 29689.9133911\n",
      "Epoch 95 completed out of 150 loss: 28360.1168823\n",
      "Epoch 96 completed out of 150 loss: 27125.9511108\n",
      "Epoch 97 completed out of 150 loss: 25922.7012329\n",
      "Epoch 98 completed out of 150 loss: 24780.5387573\n",
      "Epoch 99 completed out of 150 loss: 23707.3191528\n",
      "Epoch 100 completed out of 150 loss: 22692.5630493\n",
      "Epoch 101 completed out of 150 loss: 21710.2832642\n",
      "Epoch 102 completed out of 150 loss: 20793.4189758\n",
      "Epoch 103 completed out of 150 loss: 19917.6386108\n",
      "Epoch 104 completed out of 150 loss: 19086.8703003\n",
      "Epoch 105 completed out of 150 loss: 18299.6911621\n",
      "Epoch 106 completed out of 150 loss: 17554.2875061\n",
      "Epoch 107 completed out of 150 loss: 16833.4020691\n",
      "Epoch 108 completed out of 150 loss: 16174.882843\n",
      "Epoch 109 completed out of 150 loss: 15537.2843018\n",
      "Epoch 110 completed out of 150 loss: 14933.5362854\n",
      "Epoch 111 completed out of 150 loss: 14346.9433594\n",
      "Epoch 112 completed out of 150 loss: 13811.870575\n",
      "Epoch 113 completed out of 150 loss: 13300.4081879\n",
      "Epoch 114 completed out of 150 loss: 12792.9078979\n",
      "Epoch 115 completed out of 150 loss: 12322.4664459\n",
      "Epoch 116 completed out of 150 loss: 11889.9464111\n",
      "Epoch 117 completed out of 150 loss: 11463.7448883\n",
      "Epoch 118 completed out of 150 loss: 11063.4018555\n",
      "Epoch 119 completed out of 150 loss: 10673.0205536\n",
      "Epoch 120 completed out of 150 loss: 10294.2571564\n",
      "Epoch 121 completed out of 150 loss: 9950.24995422\n",
      "Epoch 122 completed out of 150 loss: 9607.20956421\n",
      "Epoch 123 completed out of 150 loss: 9283.40136719\n",
      "Epoch 124 completed out of 150 loss: 8981.32148743\n",
      "Epoch 125 completed out of 150 loss: 8690.58892822\n",
      "Epoch 126 completed out of 150 loss: 8405.14442444\n",
      "Epoch 127 completed out of 150 loss: 8151.78334045\n",
      "Epoch 128 completed out of 150 loss: 7883.23490906\n",
      "Epoch 129 completed out of 150 loss: 7634.24597168\n",
      "Epoch 130 completed out of 150 loss: 7410.79086304\n",
      "Epoch 131 completed out of 150 loss: 7198.84848022\n",
      "Epoch 132 completed out of 150 loss: 6976.19168091\n",
      "Epoch 133 completed out of 150 loss: 6777.89797974\n",
      "Epoch 134 completed out of 150 loss: 6569.4671936\n",
      "Epoch 135 completed out of 150 loss: 6378.09721375\n",
      "Epoch 136 completed out of 150 loss: 6202.08332062\n",
      "Epoch 137 completed out of 150 loss: 6034.92232513\n",
      "Epoch 138 completed out of 150 loss: 5860.84618378\n",
      "Epoch 139 completed out of 150 loss: 5692.92042542\n",
      "Epoch 140 completed out of 150 loss: 5549.48503876\n",
      "Epoch 141 completed out of 150 loss: 5397.03044128\n",
      "Epoch 142 completed out of 150 loss: 5262.29473877\n",
      "Epoch 143 completed out of 150 loss: 5102.45449066\n",
      "Epoch 144 completed out of 150 loss: 4976.88369751\n",
      "Epoch 145 completed out of 150 loss: 4855.753479\n",
      "Epoch 146 completed out of 150 loss: 4715.36787415\n",
      "Epoch 147 completed out of 150 loss: 4607.78527069\n",
      "Epoch 148 completed out of 150 loss: 4485.99539185\n",
      "Epoch 149 completed out of 150 loss: 4385.3844986\n",
      "Model saved in file: ./model/\n",
      "Batch # 0 Accuracy by each batch: 0.976738\n",
      "Batch # 1 Accuracy by each batch: 0.983439\n",
      "Batch # 2 Accuracy by each batch: 0.978445\n",
      "Batch # 3 Accuracy by each batch: 0.97579\n",
      "Batch # 4 Accuracy by each batch: 0.974716\n",
      "Batch # 5 Accuracy by each batch: 0.981479\n",
      "Batch # 6 Accuracy by each batch: 0.971112\n",
      "Batch # 7 Accuracy by each batch: 0.977686\n",
      "Batch # 8 Accuracy by each batch: 0.975221\n",
      "Batch # 9 Accuracy by each batch: 0.979204\n"
     ]
    }
   ],
   "source": [
    "train_neural_network(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "No variables to save",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-767d11f2501f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0msaver\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSaver\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0msaver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrestore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msess\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"./model\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Model Restored\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, var_list, reshape, sharded, max_to_keep, keep_checkpoint_every_n_hours, name, restore_sequentially, saver_def, builder, defer_build, allow_empty, write_version, pad_step_number)\u001b[0m\n\u001b[0;32m   1038\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_pad_step_number\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpad_step_number\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1039\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mdefer_build\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1040\u001b[1;33m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1041\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msaver_def\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1042\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_saver_def\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\u001b[0m in \u001b[0;36mbuild\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1059\u001b[0m           \u001b[1;32mreturn\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1060\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1061\u001b[1;33m           \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"No variables to save\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1062\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_is_empty\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1063\u001b[0m       self.saver_def = self._builder.build(\n",
      "\u001b[1;31mValueError\u001b[0m: No variables to save"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "saver = tf.train.Saver()        \n",
    "with tf.Session() as sess:\n",
    "    saver.restore(sess,\"./model\")\n",
    "    print(\"Model Restored\")\n",
    "    predictin = sess.run(lstm_neural_network, feed_dict={x:x_padded[1001],seqlen: [len(X_train[i]) for i in X_train[1001]]})    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The below code is for static_RNN and with inputs in [num_steps, batch_size, state_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "batch_size = 200\n",
    "num_steps = 791\n",
    "state_size = 200\n",
    "vocab_size = 8000\n",
    "\n",
    "\n",
    "# Placeholders\n",
    "x = tf.placeholder(tf.int32, [batch_size, None]) # [batch_size, num_steps]\n",
    "seqlen = tf.placeholder(tf.int32, [batch_size])\n",
    "y = tf.placeholder(tf.int32, [batch_size])\n",
    "keep_prob = tf.constant(1.0)\n",
    "seqlen = [len(X_train[i]) for i in X_train]\n",
    "\n",
    "\n",
    "# Embedding layer\n",
    "rnn_inputs = tf.nn.embedding_lookup(embeddings, x_padded[:batch_size])\n",
    "print(rnn_inputs)\n",
    "# RNN\n",
    "#initial_state = tf.tile(tf.get_variable('initial_state', [1, state_size],\n",
    "                        #initializer=tf.constant_initializer(0.0)),[batch_size,1])\n",
    "inputs = tf.unstack(rnn_inputs, num=num_steps, axis=1)\n",
    "print(len(list(inputs)))\n",
    "cell = tf.contrib.rnn.BasicLSTMCell(state_size) \n",
    "rnn_outputs, state = tf.contrib.rnn.static_rnn(cell, inputs, dtype=tf.float32)\n",
    "\n",
    "#cell = tf.contrib.rnn.GRUCell(state_size)\n",
    "#rnn_outputs, final_state = tf.nn.dynamic_rnn(cell, inputs, sequence_length=seqlen[:batch_size],\n",
    "                                                # initial_state=initial_state, time_major=True)\n",
    "#print(\"this is output:\", rnn_outputs)\n",
    "print(\"the lenght of output:\", len(rnn_outputs))\n",
    "\n",
    "rnn_output = tf.reshape(tf.concat(axis=1, values=rnn_outputs), [-1, state_size])\n",
    "print(\"this is the output:\",rnn_output)\n",
    "softmax_w = tf.get_variable(\"softmax_w\", [state_size, vocab_size], dtype=tf.float32)\n",
    "softmax_b = tf.get_variable(\"softmax_b\", [vocab_size], dtype=tf.float32)\n",
    "logits = tf.matmul(rnn_output, softmax_w) + softmax_b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### The below code is using a dynamic RNN with inputs [batch_size, num_steps, state_size] , this has some issue when the input is in [num_steps,batch_size,state_size] as we have to put time_major = True when we use this. \n",
    "\n",
    "Source 1: http://stackoverflow.com/questions/42513613/tensorflow-dynamic-rnn-regressor-valueerror-dimension-mismatch\n",
    "Source 2: https://www.tensorflow.org/api_docs/python/tf/nn/dynamic_rnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "batch_size = 200\n",
    "num_steps = 791\n",
    "state_size = 200\n",
    "vocab_size = 8000\n",
    "\n",
    "\n",
    "# Placeholders\n",
    "x = tf.placeholder(tf.int32, [batch_size, None]) # [batch_size, num_steps]\n",
    "seqlen = tf.placeholder(tf.int32, [batch_size])\n",
    "y = tf.placeholder(tf.int32, [batch_size])\n",
    "keep_prob = tf.constant(1.0)\n",
    "seqlen = [len(X_train[i]) for i in X_train]\n",
    "\n",
    "\n",
    "# Embedding layer\n",
    "rnn_inputs = tf.nn.embedding_lookup(embeddings, x_padded[:batch_size])\n",
    "print(rnn_inputs)\n",
    "# RNN\n",
    "initial_state = tf.tile(tf.get_variable('initial_state', [1, state_size],\n",
    "                        initializer=tf.constant_initializer(0.0)),[batch_size,1])\n",
    "#inputs = tf.unstack(rnn_inputs, num=num_steps, axis=1)\n",
    "#print(len(list(inputs)))\n",
    "#cell = tf.contrib.rnn.BasicLSTMCell(state_size) \n",
    "#rnn_outputs, state = tf.contrib.rnn.static_rnn(cell, inputs, dtype=tf.float32)\n",
    "\n",
    "cell = tf.contrib.rnn.GRUCell(state_size)\n",
    "\n",
    "rnn_outputs, final_state = tf.nn.dynamic_rnn(cell, rnn_inputs, sequence_length=seqlen[:batch_size],\n",
    "                                                 initial_state=initial_state)\n",
    "#print(\"this is output:\", rnn_outputs)\n",
    "print(\"the lenght of output:\", rnn_outputs)\n",
    "\n",
    "rnn_output = tf.reshape(tf.concat(axis=1, values=rnn_outputs), [-1, state_size])\n",
    "print(\"this is the output:\",rnn_output)\n",
    "softmax_w = tf.get_variable(\"softmax_w\", [state_size, vocab_size], dtype=tf.float32)\n",
    "softmax_b = tf.get_variable(\"softmax_b\", [vocab_size], dtype=tf.float32)\n",
    "logits = tf.matmul(rnn_output, softmax_w) + softmax_b\n",
    "logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "logits\n",
    "loss = tf.contrib.legacy_seq2seq.sequence_loss_by_example(\n",
    "        [logits],\n",
    "        [tf.reshape(y_padded[:batch_size], [-1])],\n",
    "        [tf.ones([batch_size * num_steps], dtype=tf.float32)])\n",
    "cost = tf.reduce_sum(loss) / batch_size\n",
    "optimizer = tf.train.AdamOptimizer().minimize(cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The below code is for dynamic_rnn with inputs as time_major = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "batch_size = 200\n",
    "num_steps = 791\n",
    "state_size = 200\n",
    "vocab_size = 8000\n",
    "\n",
    "\n",
    "# Placeholders\n",
    "x = tf.placeholder(tf.int32, [batch_size, None]) # [batch_size, num_steps]\n",
    "seqlen = tf.placeholder(tf.int32, [batch_size])\n",
    "y = tf.placeholder(tf.int32, [batch_size])\n",
    "keep_prob = tf.constant(1.0)\n",
    "seqlen = [len(X_train[i]) for i in X_train]\n",
    "\n",
    "\n",
    "# Embedding layer\n",
    "rnn_inputs = tf.nn.embedding_lookup(embeddings, x_padded[:batch_size])\n",
    "print(rnn_inputs)\n",
    "# RNN\n",
    "initial_state = tf.tile(tf.get_variable('initial_state', [1, state_size],\n",
    "                        initializer=tf.constant_initializer(0.0)),[batch_size,1])\n",
    "inputs = tf.unstack(rnn_inputs, num=num_steps, axis=1)\n",
    "#print(len(list(inputs)))\n",
    "#cell = tf.contrib.rnn.BasicLSTMCell(state_size) \n",
    "#rnn_outputs, state = tf.contrib.rnn.static_rnn(cell, inputs, dtype=tf.float32)\n",
    "\n",
    "cell = tf.contrib.rnn.GRUCell(state_size)\n",
    "\n",
    "rnn_outputs, final_state = tf.nn.dynamic_rnn(cell, inputs, sequence_length=seqlen[:batch_size],\n",
    "                                                 initial_state=initial_state, time_major = True)\n",
    "#print(\"this is output:\", rnn_outputs)\n",
    "print(\"the lenght of output:\", rnn_outputs)\n",
    "\n",
    "rnn_output = tf.reshape(tf.concat(axis=1, values=rnn_outputs), [-1, state_size])\n",
    "print(\"this is the output:\",rnn_output)\n",
    "softmax_w = tf.get_variable(\"softmax_w\", [state_size, vocab_size], dtype=tf.float32)\n",
    "softmax_b = tf.get_variable(\"softmax_b\", [vocab_size], dtype=tf.float32)\n",
    "logits = tf.matmul(rnn_output, softmax_w) + softmax_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
